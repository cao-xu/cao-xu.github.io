<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.1">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.1">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.1" color="#222">
  <link rel="alternate" href="/atom.xml" title="CaoXu's Blog" type="application/atom+xml">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">
  <meta name="baidu-site-verification" content="cwgyC92bKt">

<link rel="stylesheet" href="/css/main.css?v=7.4.1">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.4.1',
    exturl: true,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":"flat"},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"manual"},
    fancybox: false,
    mediumzoom: true,
    lazyload: true,
    pangu: true,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":5,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="这是我个人博客的第一篇文章，是全新的开始。希望未来在这里记录更多有趣的探索。    自动驾驶随着人工智能技术的成熟，人才需求在不断增加，为了对我国自动驾驶人才需求进行了解，本文选择BOSS直聘招聘网站获取自动驾驶相关职位信息，分析数据，根据分析结果确定人才需求、为以后的学习制定计划。">
<meta name="keywords" content="python,爬虫,工作信息,可视化,pyecharts">
<meta property="og:type" content="article">
<meta property="og:title" content="BOSS直聘“自动驾驶”岗位信息爬取与分析">
<meta property="og:url" content="http://www.caoxu.club/2019/10/17/BOSS直聘爬虫/index.html">
<meta property="og:site_name" content="CaoXu&#39;s Blog">
<meta property="og:description" content="这是我个人博客的第一篇文章，是全新的开始。希望未来在这里记录更多有趣的探索。    自动驾驶随着人工智能技术的成熟，人才需求在不断增加，为了对我国自动驾驶人才需求进行了解，本文选择BOSS直聘招聘网站获取自动驾驶相关职位信息，分析数据，根据分析结果确定人才需求、为以后的学习制定计划。">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-10-21T01:49:46.160Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="BOSS直聘“自动驾驶”岗位信息爬取与分析">
<meta name="twitter:description" content="这是我个人博客的第一篇文章，是全新的开始。希望未来在这里记录更多有趣的探索。    自动驾驶随着人工智能技术的成熟，人才需求在不断增加，为了对我国自动驾驶人才需求进行了解，本文选择BOSS直聘招聘网站获取自动驾驶相关职位信息，分析数据，根据分析结果确定人才需求、为以后的学习制定计划。">
  <link rel="canonical" href="http://www.caoxu.club/2019/10/17/BOSS直聘爬虫/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>
<link rel="stylesheet" href="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.css"><style>
#needsharebutton-postbottom {
  cursor: pointer;
  height: 26px;
  margin-top: 10px;
  position: relative;
}
#needsharebutton-postbottom .btn {
  border: 1px solid $btn-default-border-color;
  border-radius: 3px;
  display: initial;
  padding: 1px 4px;
}
</style>
  <title>BOSS直聘“自动驾驶”岗位信息爬取与分析 | CaoXu's Blog</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-149899840-1"></script>
    <script pjax>
      var host = window.location.hostname;
      if (host !== "localhost" || !true) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-149899840-1');
      }
    </script>
  


  <script pjax>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?9a64574f94b7d9fe418e05e7e891ef74";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">CaoXu's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">想法、创意与实践</p>
      
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
        
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      
    
      
      
        
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
      
    
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger">
        
          <i class="fa fa-search fa-fw"></i>
        
        搜索
        </a>
      </li>
    
  </ul>

    

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL2Nhby14dQ==" title="cao-xu GitHub" aria-label="cao-xu GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></span>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://www.caoxu.club/2019/10/17/BOSS直聘爬虫/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="CaoXu">
      <meta itemprop="description" content="记录在技术学习道路上的点点滴滴，分享有趣的项目经验">
      <meta itemprop="image" content="/images/android-chrome-512x512.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="CaoXu's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          
            BOSS直聘“自动驾驶”岗位信息爬取与分析
            

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2019-10-17 15:40:49" itemprop="dateCreated datePublished" datetime="2019-10-17T15:40:49+08:00">2019-10-17</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-10-21 09:49:46" itemprop="dateModified" datetime="2019-10-21T09:49:46+08:00">2019-10-21</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/2019秋《交通数据分析》/" itemprop="url" rel="index">
                    <span itemprop="name">2019秋《交通数据分析》</span>
                  </a>
                </span>

                
                
                  ，
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/2019秋《交通数据分析》/数据爬取/" itemprop="url" rel="index">
                    <span itemprop="name">数据爬取</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
          
          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              
                <span class="post-meta-item-text">本文字数：</span>
              
              <span>26k</span>
            </span>
          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              
              <span>24 分钟</span>
            </span>
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>  这是我个人博客的第一篇文章，是全新的开始。希望未来在这里记录更多有趣的探索。</p>
<img title="自动驾驶岗位名称" data-src="/2019/10/17/BOSS直聘爬虫/岗位名称.jpg">
<p>  自动驾驶随着人工智能技术的成熟，人才需求在不断增加，为了对我国自动驾驶人才需求进行了解，本文选择<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpcGluLmNvbQ==" title="https://www.zhipin.com">BOSS直聘<i class="fa fa-external-link"></i></span>招聘网站获取自动驾驶相关职位信息，分析数据，根据分析结果确定人才需求、为以后的学习制定计划。<br><a id="more"></a></p>
<p>本文开发环境：<span class="exturl" data-url="aHR0cHM6Ly93d3cucHl0aG9uLm9yZw==" title="https://www.python.org">python3.7<i class="fa fa-external-link"></i></span> 、<span class="exturl" data-url="aHR0cHM6Ly93d3cuYW5hY29uZGEuY29t" title="https://www.anaconda.com">anconda3<i class="fa fa-external-link"></i></span></p>
<h2 id="一、数据爬取"><a href="#一、数据爬取" class="headerlink" title="一、数据爬取"></a>一、数据爬取</h2><h3 id="1-1-分析目标页，构造URL"><a href="#1-1-分析目标页，构造URL" class="headerlink" title="1.1 分析目标页，构造URL"></a>1.1 分析目标页，构造URL</h3><p>  首先，进入网站输入关键字“自动驾驶”查询得到职位的列表页面，对目标页面的URL分析<code>https://www.zhipin.com/c101010100/?query=自动驾驶&amp;page=1&amp;ka=page-1</code>，发现关键的字段有：<code>query</code>、<code>page</code>分别代表了要查询的<strong>关键字</strong>和<strong>页面</strong>，<code>c101010100</code>代表了城市的编号，当选择了<strong>全国</strong>时编号为<code>c101010100</code>，所以通过控制这三个参数，实现对全国所有职位列表页的信息的爬取。</p>
<img title="目标页面" data-src="/2019/10/17/BOSS直聘爬虫/图1-1目标页面.png">
<center>图1-1  目标页面</center>

<p>  其次，构建headers cookie，通过尝试发现爬取Boss直聘必须添加cookie，构建的请求头如下。</p>
<p><code>header = {
         'User-Agent':
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36',
         'Cookie':
            '_uab_collina=156967238793885639512262；bannerClose_wanmeishijie=true; lastCity=101010100; _bl_uid=q5k7F1m8aOIjLLybtrIhbILink0X; __c=1570153169; __g=-;Hm_lvt_194df3105ad7148dcf2b98a91b5e727a=1569912508,1569985933,1570068443,1570153169;__l=l=%2Fwww.zhipin.com%2F&amp;r=&amp;friend_source=0&amp;friend_source=0;toUrl=https%3A%2F%2Fwww.zhipin.com%2Fjob_detail%2F%3Fquery%3D%25E8%2587%25AA%25E5%258A%25A8%25E9%25A9%25BE%25E9%25A9%25B6%26city%3D101020100%26industry%3D%26position%3D;__zp_stoken__=eaf4AHdTnnRrM4tosXCE%2FCPA2IBqs%2BoMIR%2FkL2KsnUmYiwLERJs40PPb8KIurKugecg3l0jmgV1zyN86oQkjtd81dw%3D%3D;Hm_lpvt_194df3105ad7148dcf2b98a91b5e727a=1570159163;__a=64007787.1569672388.1570068443.1570153169.178.6.23.172;__zp_sseed__=4qNlVc1nPWG9Y7G66QfbgtQFW6iSHevalYp+HzrGFH4=; __zp_sname__=9d9e2c78;__zp_sts__=1570159388399'
        }</code></p>
<h3 id="1-2-爬取、解析数据并保存"><a href="#1-2-爬取、解析数据并保存" class="headerlink" title="1.2 爬取、解析数据并保存"></a>1.2 爬取、解析数据并保存</h3><h4 id="1-2-1-确定要爬取的信息"><a href="#1-2-1-确定要爬取的信息" class="headerlink" title="1.2.1 确定要爬取的信息"></a>1.2.1 确定要爬取的信息</h4><p>  F12打开开发者工具，审查网页元素，需要获取的信息包括“工作名、薪资、工作地点、工作经验、学历要求、企业名、企业所属行业”。</p>
<img title="目标页面" data-src="/2019/10/17/BOSS直聘爬虫/图1-2分析目标页面.png">
<center>图1-2  分析目标页面</center>

<h4 id="1-2-2-发送请求、解析数据、保存数据"><a href="#1-2-2-发送请求、解析数据、保存数据" class="headerlink" title="1.2.2 发送请求、解析数据、保存数据"></a>1.2.2 发送请求、解析数据、保存数据</h4><p>  对目标页面发送请求后，解析返回的html并提取所需要的信息，这里主要用到的包有：<code>urllib</code>、<code>requests</code>、<code>BeautifulSoup</code>、<code>lxml</code>。函数的主要步骤为：</p>
<ul>
<li>第一步，请求目标页面html</li>
<li>第二步，使用<code>lxml</code>和<code>bs4</code>解析目标信息</li>
<li>第三步，随机等待几秒，防止ip被封</li>
</ul>
<p>循环完成对所有页面岗位信息的提取，当完成数据的解析后，将数据保存到Excel表格中。下面的代码实现上述发送请求、解析数据、保存数据步骤。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_detial</span><span class="params">(total_page_count)</span>:</span></span><br><span class="line">    <span class="comment">#循环所有页面，</span></span><br><span class="line">    <span class="comment">#第一步，构造URL获取html</span></span><br><span class="line">    <span class="comment">#第二步，使用bs4解析详情页的超链接，保存到数组中</span></span><br><span class="line">    key_words = <span class="string">"自动驾驶"</span></span><br><span class="line">    key = urllib.parse.quote(key_words) <span class="comment">#将中文进行转码</span></span><br><span class="line">    jobs_title_list = []</span><br><span class="line">    area_list = []</span><br><span class="line">    work_exp_list = []</span><br><span class="line">    edu_list = []</span><br><span class="line">    company_list = []</span><br><span class="line">    salary_list = []</span><br><span class="line">    industry_list = []</span><br><span class="line">    financing_stage_list = []</span><br><span class="line">    company_scale_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,total_page_count+<span class="number">1</span>):   <span class="comment">#查看页面有10页职位列表</span></span><br><span class="line">        print(<span class="string">"正在爬取第 %s 页列表页..."</span> % i)</span><br><span class="line">        url =<span class="string">'https://www.zhipin.com/c100010000/?query='</span>+key+<span class="string">'&amp;page='</span>+str(i)+<span class="string">'&amp;ka=page-'</span>+str(i)</span><br><span class="line">        <span class="comment">#获取每页的列表html</span></span><br><span class="line">        per_page_html = get_job_html(url) </span><br><span class="line">        <span class="comment">#解析提取详情页超的数据</span></span><br><span class="line">        jobs_title,area,work_exp,edu,company,salary,industry\</span><br><span class="line">            =  parse_job_detial(per_page_html) <span class="comment">#,company_scale,financing_stage</span></span><br><span class="line">        <span class="comment"># 将每页30个数据尾加到总的数组</span></span><br><span class="line">        jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list\</span><br><span class="line">            = append_job_detial(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list,\</span><br><span class="line">                jobs_title,area,work_exp,edu,company,salary,industry) </span><br><span class="line">        <span class="comment">#随机等待,防止封ip</span></span><br><span class="line">        span=round(random.random()*<span class="number">6</span>,<span class="number">1</span>)</span><br><span class="line">        time.sleep(span)</span><br><span class="line">    print(<span class="string">"爬取列表页完成！"</span>)</span><br><span class="line">    <span class="comment"># 将爬取的数据保存到Excel</span></span><br><span class="line">    jobs_data = list(zip(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list)) </span><br><span class="line">    jobs_data.insert(<span class="number">0</span>, (<span class="string">"岗位"</span>,<span class="string">"工作地点"</span>,<span class="string">"工作经验要求"</span>,<span class="string">"学历要求"</span>,<span class="string">"招聘公司"</span>,<span class="string">"工资"</span>,<span class="string">"所属行业"</span>))</span><br><span class="line">    save_to_excel(<span class="string">"jobData"</span>, <span class="string">"AutoDriving"</span>, jobs_data) <span class="comment">#fileName,SheetName,数据</span></span><br><span class="line">    print(<span class="string">"保存数据成功，打开jobData.xls查看"</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>  <code>get_job_html(url)</code>函数实现请求目标<code>url</code>，代码实现如下。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_job_html</span><span class="params">(url)</span>:</span></span><br><span class="line">    header = {</span><br><span class="line">         <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'</span>,</span><br><span class="line">         <span class="string">'Cookie'</span>:<span class="string">'_uab_collina=156967238793885639512262; bannerClose_wanmeishijie=true; lastCity=101010100; _bl_uid=q5k7F1m8aOIjLLybtrIhbILink0X; __c=1570153169; __g=-; Hm_lvt_194df3105ad7148dcf2b98a91b5e727a=1569912508,1569985933,1570068443,1570153169; __l=l=%2Fwww.zhipin.com%2F&amp;r=&amp;friend_source=0&amp;friend_source=0; toUrl=https%3A%2F%2Fwww.zhipin.com%2Fjob_detail%2F%3Fquery%3D%25E8%2587%25AA%25E5%258A%25A8%25E9%25A9%25BE%25E9%25A9%25B6%26city%3D101020100%26industry%3D%26position%3D; __zp_stoken__=eaf4AHdTnnRrM4tosXCE%2FCPA2IBqs%2BoMIR%2FkL2KsnUmYiwLERJs40PPb8KIurKugecg3l0jmgV1zyN86oQkjtd81dw%3D%3D; Hm_lpvt_194df3105ad7148dcf2b98a91b5e727a=1570159163; __a=64007787.1569672388.1570068443.1570153169.178.6.23.172; __zp_sseed__=4qNlVc1nPWG9Y7G66QfbgtQFW6iSHevalYp+HzrGFH4=; __zp_sname__=9d9e2c78; __zp_sts__=1570159388399'</span></span><br><span class="line">         }</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        html = requests.get(url,headers = header)</span><br><span class="line">        <span class="keyword">if</span> html.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> html.text <span class="comment">#返回列表页的html</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">except</span> RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></tbody></table></figure>
<p>  获取到网页html后解析想要的数据，实现代码如下。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_job_detial</span><span class="params">(per_page_html)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> per_page_html==<span class="string">''</span> <span class="keyword">or</span> len(per_page_html)==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"未请求到列表页的html！"</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        jobs_title = []</span><br><span class="line">        area = []</span><br><span class="line">        work_exp = []</span><br><span class="line">        edu = []</span><br><span class="line">        company = []</span><br><span class="line">        salary = []</span><br><span class="line">        industry = []</span><br><span class="line">        financing_stage = []</span><br><span class="line">        company_scale = []</span><br><span class="line">        <span class="comment"># 初始化 标准化html</span></span><br><span class="line">        html = etree.HTML(per_page_html) </span><br><span class="line">        <span class="comment"># 工作名</span></span><br><span class="line">        jobs_title = html.xpath(<span class="string">'//div[@class="job-title"]/text()'</span>)</span><br><span class="line">        <span class="comment">#print(jobs_title)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment"># 工作地点</span></span><br><span class="line">        area = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[1]'</span>)</span><br><span class="line">        <span class="comment">#print(area)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#工作经验要求</span></span><br><span class="line">        work_exp = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[2]'</span>)</span><br><span class="line">        <span class="comment">#print(work_exp)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#学历要求</span></span><br><span class="line">        edu = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[3]'</span>)</span><br><span class="line">        <span class="comment">#print(edu)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#公司名</span></span><br><span class="line">        company = html.xpath(<span class="string">'//div[@class="company-text"]//a/text()'</span>)</span><br><span class="line">        <span class="comment">#print(company)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment"># 工资</span></span><br><span class="line">        salary = html.xpath(<span class="string">'//div[@class="info-primary"]//span[@class="red"]/text()'</span>)</span><br><span class="line">        <span class="comment">#print(salary)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#所属行业</span></span><br><span class="line">        industry = html.xpath(<span class="string">'//div[@class="info-company"]//p/text()[1]'</span>)</span><br><span class="line">        <span class="keyword">return</span> jobs_title,area,work_exp,edu,company,salary,industry</span><br></pre></td></tr></tbody></table></figure>
<p>  每次获取的是一页职位列表信息，需要将每次的数据尾加到总的数据<code>list</code>中，代码实现如下。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append_job_detial</span><span class="params">(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list,jobs_title,area,work_exp,edu,company,salary,industry)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i,info <span class="keyword">in</span> enumerate(jobs_title):</span><br><span class="line">        jobs_title_list.append(jobs_title[i])</span><br><span class="line">        area_list.append(area[i])</span><br><span class="line">        work_exp_list.append(work_exp[i])</span><br><span class="line">        edu_list.append(edu[i])</span><br><span class="line">        company_list.append(company[i])</span><br><span class="line">        salary_list.append(salary[i])</span><br><span class="line">        industry_list.append(industry[i])</span><br><span class="line">    <span class="keyword">return</span> jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list</span><br></pre></td></tr></tbody></table></figure>
<p>  当所有页面的数据获取解析完成后，将数据保存为Excel的形式，代码实现：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_excel</span><span class="params">(filename,sheet_name,data)</span>:</span></span><br><span class="line">    f = xlwt.Workbook(encoding=<span class="string">'utf-8'</span>)  <span class="comment">#创建一个Workbook 设置编码</span></span><br><span class="line">    <span class="comment"># 第二参数表示是否可以覆盖单元格 其实是 Workbook实例化的一个参数，默认值为False</span></span><br><span class="line">    sheet = f.add_sheet(sheet_name,cell_overwrite_ok=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，</span></span><br><span class="line">    <span class="comment"># 同时列出数据和数据下标，一般用在 for 循环当中。</span></span><br><span class="line">    <span class="keyword">for</span> row,row_data <span class="keyword">in</span> enumerate(data):  <span class="comment">#处理行</span></span><br><span class="line">        <span class="keyword">for</span> column,column_data <span class="keyword">in</span> enumerate(row_data): <span class="comment">#处理列</span></span><br><span class="line">            sheet.write(row,column,str(column_data))</span><br><span class="line">    f.save(filename + <span class="string">".xls"</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>  对整个过程的代码集成如下。</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree <span class="comment">#xpath</span></span><br><span class="line"><span class="keyword">from</span> requests.exceptions <span class="keyword">import</span> RequestException</span><br><span class="line"><span class="keyword">import</span> xlwt       <span class="comment">#excel操作</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_job_html</span><span class="params">(url)</span>:</span></span><br><span class="line">    header = {</span><br><span class="line">         <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'</span>,</span><br><span class="line">         <span class="string">'Cookie'</span>:<span class="string">'_uab_collina=156967238793885639512262; bannerClose_wanmeishijie=true; lastCity=101010100; _bl_uid=q5k7F1m8aOIjLLybtrIhbILink0X; __c=1570153169; __g=-; Hm_lvt_194df3105ad7148dcf2b98a91b5e727a=1569912508,1569985933,1570068443,1570153169; __l=l=%2Fwww.zhipin.com%2F&amp;r=&amp;friend_source=0&amp;friend_source=0; toUrl=https%3A%2F%2Fwww.zhipin.com%2Fjob_detail%2F%3Fquery%3D%25E8%2587%25AA%25E5%258A%25A8%25E9%25A9%25BE%25E9%25A9%25B6%26city%3D101020100%26industry%3D%26position%3D; __zp_stoken__=eaf4AHdTnnRrM4tosXCE%2FCPA2IBqs%2BoMIR%2FkL2KsnUmYiwLERJs40PPb8KIurKugecg3l0jmgV1zyN86oQkjtd81dw%3D%3D; Hm_lpvt_194df3105ad7148dcf2b98a91b5e727a=1570159163; __a=64007787.1569672388.1570068443.1570153169.178.6.23.172; __zp_sseed__=4qNlVc1nPWG9Y7G66QfbgtQFW6iSHevalYp+HzrGFH4=; __zp_sname__=9d9e2c78; __zp_sts__=1570159388399'</span></span><br><span class="line">         }</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        html = requests.get(url,headers = header)</span><br><span class="line">        <span class="keyword">if</span> html.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> html.text <span class="comment">#返回列表页的html</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">except</span> RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_job_detial</span><span class="params">(per_page_html)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> per_page_html==<span class="string">''</span> <span class="keyword">or</span> len(per_page_html)==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"未请求到列表页的html！"</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        jobs_title = []</span><br><span class="line">        area = []</span><br><span class="line">        work_exp = []</span><br><span class="line">        edu = []</span><br><span class="line">        company = []</span><br><span class="line">        salary = []</span><br><span class="line">        industry = []</span><br><span class="line">        financing_stage = []</span><br><span class="line">        company_scale = []</span><br><span class="line">        <span class="comment"># 初始化 标准化html</span></span><br><span class="line">        html = etree.HTML(per_page_html) </span><br><span class="line">        <span class="comment"># 工作名</span></span><br><span class="line">        jobs_title = html.xpath(<span class="string">'//div[@class="job-title"]/text()'</span>)</span><br><span class="line">        <span class="comment">#print(jobs_title)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment"># 工作地点</span></span><br><span class="line">        area = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[1]'</span>)</span><br><span class="line">        <span class="comment">#print(area)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#工作经验要求</span></span><br><span class="line">        work_exp = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[2]'</span>)</span><br><span class="line">        <span class="comment">#print(work_exp)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#学历要求</span></span><br><span class="line">        edu = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[3]'</span>)</span><br><span class="line">        <span class="comment">#print(edu)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#公司名</span></span><br><span class="line">        company = html.xpath(<span class="string">'//div[@class="company-text"]//a/text()'</span>)</span><br><span class="line">        <span class="comment">#print(company)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment"># 工资</span></span><br><span class="line">        salary = html.xpath(<span class="string">'//div[@class="info-primary"]//span[@class="red"]/text()'</span>)</span><br><span class="line">        <span class="comment">#print(salary)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#所属行业</span></span><br><span class="line">        industry = html.xpath(<span class="string">'//div[@class="info-company"]//p/text()[1]'</span>)</span><br><span class="line">        <span class="keyword">return</span> jobs_title,area,work_exp,edu,company,salary,industry</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append_job_detial</span><span class="params">(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list,jobs_title,area,work_exp,edu,company,salary,industry)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i,info <span class="keyword">in</span> enumerate(jobs_title):</span><br><span class="line">        jobs_title_list.append(jobs_title[i])</span><br><span class="line">        area_list.append(area[i])</span><br><span class="line">        work_exp_list.append(work_exp[i])</span><br><span class="line">        edu_list.append(edu[i])</span><br><span class="line">        company_list.append(company[i])</span><br><span class="line">        salary_list.append(salary[i])</span><br><span class="line">        industry_list.append(industry[i])</span><br><span class="line">    <span class="keyword">return</span> jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_excel</span><span class="params">(filename,sheet_name,data)</span>:</span></span><br><span class="line">    f = xlwt.Workbook(encoding=<span class="string">'utf-8'</span>)  <span class="comment">#创建一个Workbook 设置编码</span></span><br><span class="line">    <span class="comment"># 第二参数表示是否可以覆盖单元格 其实是 Workbook实例化的一个参数，默认值为False</span></span><br><span class="line">    sheet = f.add_sheet(sheet_name,cell_overwrite_ok=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，</span></span><br><span class="line">    <span class="comment"># 同时列出数据和数据下标，一般用在 for 循环当中。</span></span><br><span class="line">    <span class="keyword">for</span> row,row_data <span class="keyword">in</span> enumerate(data):  <span class="comment">#处理行</span></span><br><span class="line">        <span class="keyword">for</span> column,column_data <span class="keyword">in</span> enumerate(row_data): <span class="comment">#处理列</span></span><br><span class="line">            sheet.write(row,column,str(column_data))</span><br><span class="line">    f.save(filename + <span class="string">".xls"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_detial</span><span class="params">(total_page_count)</span>:</span></span><br><span class="line">    <span class="comment">#循环所有页面，</span></span><br><span class="line">    <span class="comment">#第一步，构造URL获取html</span></span><br><span class="line">    <span class="comment">#第二步，使用bs4解析详情页的超链接，保存到数组中</span></span><br><span class="line">    key_words = <span class="string">"自动驾驶"</span></span><br><span class="line">    key = urllib.parse.quote(key_words) <span class="comment">#将中文进行转码</span></span><br><span class="line">    jobs_title_list = []</span><br><span class="line">    area_list = []</span><br><span class="line">    work_exp_list = []</span><br><span class="line">    edu_list = []</span><br><span class="line">    company_list = []</span><br><span class="line">    salary_list = []</span><br><span class="line">    industry_list = []</span><br><span class="line">    financing_stage_list = []</span><br><span class="line">    company_scale_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,total_page_count+<span class="number">1</span>):   <span class="comment">#查看页面有10页职位列表</span></span><br><span class="line">        print(<span class="string">"正在爬取第 %s 页列表页..."</span> % i)</span><br><span class="line">        url =<span class="string">'https://www.zhipin.com/c100010000/?query='</span>+key+<span class="string">'&amp;page='</span>+str(i)+<span class="string">'&amp;ka=page-'</span>+str(i)</span><br><span class="line">        <span class="comment">#获取每页的列表html</span></span><br><span class="line">        per_page_html = get_job_html(url) </span><br><span class="line">        <span class="comment">#解析提取详情页超的数据</span></span><br><span class="line">        jobs_title,area,work_exp,edu,company,salary,industry\</span><br><span class="line">            =  parse_job_detial(per_page_html) <span class="comment">#,company_scale,financing_stage</span></span><br><span class="line">        <span class="comment"># 将每页30个数据尾加到总的数组</span></span><br><span class="line">        jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list\</span><br><span class="line">            = append_job_detial(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list,\</span><br><span class="line">                jobs_title,area,work_exp,edu,company,salary,industry) <span class="comment">#,financing_stage_list,financing_stage,financing_stage_list,company_scale,,company_scale_list,company_scale_list,</span></span><br><span class="line">        <span class="comment">#随机等待,防止封ip</span></span><br><span class="line">        span=round(random.random()*<span class="number">6</span>,<span class="number">1</span>)</span><br><span class="line">        time.sleep(span)</span><br><span class="line">    print(<span class="string">"爬取列表页完成！"</span>)</span><br><span class="line">    <span class="comment"># 将爬取的数据保存到Excel</span></span><br><span class="line">    jobs_data = list(zip(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list)) <span class="comment">#,company_scale_list</span></span><br><span class="line">    jobs_data.insert(<span class="number">0</span>, (<span class="string">"岗位"</span>,<span class="string">"工作地点"</span>,<span class="string">"工作经验要求"</span>,<span class="string">"学历要求"</span>,<span class="string">"招聘公司"</span>,<span class="string">"工资"</span>,<span class="string">"所属行业"</span>))  <span class="comment">#,"公司规模"</span></span><br><span class="line">    save_to_excel(<span class="string">"jobData"</span>, <span class="string">"AutoDriving"</span>, jobs_data) <span class="comment">#fileName,SheetName,数据</span></span><br><span class="line">    print(<span class="string">"保存数据成功，打开jobData.xls查看"</span>)</span><br><span class="line"></span><br><span class="line">total_page_count = <span class="number">10</span> <span class="comment">#设置爬取列表页页数，10页</span></span><br><span class="line">get_all_detial(total_page_count) <span class="comment">#获取工作的数据保存到Excel</span></span><br></pre></td></tr></tbody></table></figure>
<img title="获取的数据" data-src="/2019/10/17/BOSS直聘爬虫/图1-4获取的数据.png">
<center>图1-4  获取的数据</center>

<p>  图1-4为获取的目标数据，一共抓取了120个岗位信息。下一步就是对获取的信息进行清洗和统计分析。</p>
<h2 id="二、数据分析"><a href="#二、数据分析" class="headerlink" title="二、数据分析"></a>二、数据分析</h2><p>  本节主要介绍我们关心哪些信息，并如何对这些的数据进行分析处理和可视化，从而从这些数据中提取出有价值的信息。</p>
<h3 id="2-1-工作地点全国分布"><a href="#2-1-工作地点全国分布" class="headerlink" title="2.1 工作地点全国分布"></a>2.1 工作地点全国分布</h3><p>  找工作首先关注的点应该是“在哪”工作，找到一个房价便宜工资很高的工作应该是绝大多数求职者的最佳选择。那么“自动驾驶”相关岗位在全国范围内的分布是什么样的情况，本文通过使用优秀的可视化包pyecharts<sup>[1]</sup>实现对招聘岗位全国的分布情况的分析。</p>
<p><strong>在制作过程中pyecharts的<span class="exturl" data-url="aHR0cHM6Ly9weWVjaGFydHMub3JnLyMvemgtY24v" title="https://pyecharts.org/#/zh-cn/">官方文档<i class="fa fa-external-link"></i></span>起到了很大的作用，以后在开发过程中要重视官方文档的使用。</strong></p>
<img title="图2-1 自动驾驶职位招聘全国分布" data-src="/2019/10/17/BOSS直聘爬虫/图2-1%20自动驾驶职位招聘全国分布.png">
<center>图2-1 自动驾驶职位招聘全国分布</center>

<img title="图2-2  自动驾驶岗位数量全国TOP10城市" data-src="/2019/10/17/BOSS直聘爬虫/图2-2%20%20自动驾驶岗位数量全国TOP10城市.png">
<center>图2-2  自动驾驶岗位数量全国TOP10城市</center>

<p>代码实现</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Geo</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Bar</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> pyecharts.globals <span class="keyword">import</span> GeoType</span><br><span class="line"><span class="keyword">from</span> pyecharts.render <span class="keyword">import</span> make_snapshot</span><br><span class="line"><span class="keyword">from</span> snapshot_selenium <span class="keyword">import</span> snapshot</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">city_counter</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    全国工作分布热力图</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    datas = pd.read_excel(<span class="string">'jobData.xls'</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">    datas_copy = datas</span><br><span class="line">    datas_copy[<span class="string">'工作地点'</span>] = datas_copy[<span class="string">'工作地点'</span>].apply(<span class="keyword">lambda</span> x :x.split(<span class="string">' '</span>)[<span class="number">0</span>])</span><br><span class="line">    grouped_city = datas_copy.groupby(datas[<span class="string">'工作地点'</span>])</span><br><span class="line">    grouped_city_count = grouped_city[<span class="string">'工作地点'</span>].agg([<span class="string">'count'</span>])    <span class="comment"># 对城市数量进行统计</span></span><br><span class="line">    grouped_city_count.reset_index(inplace = <span class="literal">True</span>)                  <span class="comment"># 若不进行此操作，将会报错 </span></span><br><span class="line">    city_data = [(grouped_city_count[<span class="string">'工作地点'</span>][i], grouped_city_count[<span class="string">'count'</span>][i]) <span class="keyword">for</span> i <span class="keyword">in</span> range(grouped_city_count.shape[<span class="number">0</span>])]</span><br><span class="line">    <span class="comment">#print(city_data)</span></span><br><span class="line">    attr = []</span><br><span class="line">    value = []</span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> city_data:</span><br><span class="line">        attrSub = re.findall(<span class="string">r'[(](.*?)[)]'</span>, str(obj))[<span class="number">0</span>].split(<span class="string">','</span>)[<span class="number">0</span>]</span><br><span class="line">        attr.append(attrSub.split(<span class="string">"'"</span>)[<span class="number">1</span>])</span><br><span class="line">        value.append(int(re.findall(<span class="string">r'[(](.*?)[)]'</span>, str(obj))[<span class="number">0</span>].split(<span class="string">','</span>)[<span class="number">1</span>].strip()))</span><br><span class="line">    <span class="comment">#print(attr)</span></span><br><span class="line">    <span class="comment">#print(value)</span></span><br><span class="line">    <span class="comment"># 全国工作分布热力图</span></span><br><span class="line">    geo = Geo()</span><br><span class="line">    geo = (</span><br><span class="line">        Geo()</span><br><span class="line">        .add_schema(maptype=<span class="string">"china"</span>)</span><br><span class="line">        .add(<span class="string">"岗位数"</span>,[list(z) <span class="keyword">for</span> z <span class="keyword">in</span> zip(attr, value)],symbol_size = <span class="number">20</span>)</span><br><span class="line">        .set_series_opts(label_opts=opts.LabelOpts(is_show=<span class="literal">False</span>)) <span class="comment">#设置图例不可见</span></span><br><span class="line">        .set_global_opts(visualmap_opts=opts.VisualMapOpts(min_=<span class="number">0</span>,max_=<span class="number">40</span>),title_opts=opts.TitleOpts(title=<span class="string">"自动驾驶职位招聘地理位置"</span>))</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">#geo.render('自动驾驶岗位全国热力图.html')</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 全国招聘职位top10地区</span></span><br><span class="line">    city_top10 = sorted(city_data, key = <span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse = <span class="literal">True</span>)[<span class="number">0</span>:<span class="number">10</span>]</span><br><span class="line">    attr = []</span><br><span class="line">    value = []</span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> city_top10:</span><br><span class="line">        attrSub = re.findall(<span class="string">r'[(](.*?)[)]'</span>, str(obj))[<span class="number">0</span>].split(<span class="string">','</span>)[<span class="number">0</span>]</span><br><span class="line">        attr.append(attrSub.split(<span class="string">"'"</span>)[<span class="number">1</span>])</span><br><span class="line">        value.append(int(re.findall(<span class="string">r'[(](.*?)[)]'</span>, str(obj))[<span class="number">0</span>].split(<span class="string">','</span>)[<span class="number">1</span>].strip()))</span><br><span class="line">    bar = (</span><br><span class="line">        Bar()</span><br><span class="line">        .add_xaxis(attr)</span><br><span class="line">        .add_yaxis(<span class="string">"招聘数量"</span>,value)</span><br><span class="line">        .set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"自动驾驶岗位分布柱状图"</span>))</span><br><span class="line">        )</span><br><span class="line">    <span class="comment">#bar.render()</span></span><br><span class="line">    <span class="keyword">return</span> geo,bar</span><br><span class="line"></span><br><span class="line">geo,bar = city_counter()</span><br><span class="line">geo.render(<span class="string">'自动驾驶岗位全国热力图.html'</span>)</span><br><span class="line">bar.render(<span class="string">'自动驾驶岗位分布柱状图.html'</span>)</span><br><span class="line"><span class="comment">#make_snapshot(snapshot, geo.render(), "自动驾驶岗位全国热力图.png") # 使用此语句可直接生成图片</span></span><br><span class="line"><span class="comment">#make_snapshot(snapshot, bar.render(), "自动驾驶岗位分布柱状图.png") # 使用此语句可直接生成图片</span></span><br></pre></td></tr></tbody></table></figure>
<p>  从图中可以看出“自动驾驶”岗位主要分布在北京、上海、深圳、武汉、苏州、杭州等一线、二线城市，北京、江浙沪（包邮区）和深圳是主要阵地，如果想要从事这个领域的工作，到这些城市去发展有好的环境。</p>
<h3 id="2-2-薪资水平"><a href="#2-2-薪资水平" class="headerlink" title="2.2 薪资水平"></a>2.2 薪资水平</h3><p>  找工作更重要的是薪资的水平，辛辛苦苦学了很多技能和知识就是为了获得更多的薪资。所以我们来看一下“自动驾驶”岗位的全国范围的薪资水平是怎样的。本文对获取的数据按照城市分类，计算了各个城市的平均薪资水平，如图2-3所示。</p>
<img title="图2-3  自动驾驶全国平均薪资水平统计" data-src="/2019/10/17/BOSS直聘爬虫/图2-3%20%20自动驾驶全国平均薪资水平统计.png">
<center>图2-3  自动驾驶全国平均薪资水平统计</center>

<p>  从图中可以看出，杭州以35K的平均月薪位居全国第一，全国范围内的平均薪资为18422元/月，佛山最低仅有5000元/月。月薪超过全国平均水平的数量超总体的60%。可以看出，薪资水平最高的城市在杭州、北京、上海、深圳等一线城市，杭州的物价水平和房价低于北上广等城市，落户和生活的成本与北上广相比较低，是一个不错的选择。</p>
<p>代码实现</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Bar</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> pyecharts.render <span class="keyword">import</span> make_snapshot</span><br><span class="line"><span class="keyword">from</span> snapshot_selenium <span class="keyword">import</span> snapshot</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deal_salary</span><span class="params">(salary_data)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> re.match(<span class="string">'.*K'</span>,salary_data):</span><br><span class="line">        <span class="comment"># 计算平均工资</span></span><br><span class="line">        <span class="keyword">return</span> int(float((float(re.findall(<span class="string">r'(.*?)K'</span>,salary_data)[<span class="number">0</span>].split(<span class="string">'-'</span>)[<span class="number">0</span>])*<span class="number">1000</span>+\</span><br><span class="line">            float(re.findall(<span class="string">r'(.*?)K'</span>,salary_data)[<span class="number">0</span>].split(<span class="string">'-'</span>)[<span class="number">1</span>])*<span class="number">1000</span>)/<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">city_salary</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">	每个城市的平均工资条形统计图</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">    datas = pd.read_excel(<span class="string">'jobData.xls'</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">    datas_copy = datas</span><br><span class="line">    datas_copy[<span class="string">'工作地点'</span>] = datas_copy[<span class="string">'工作地点'</span>].apply(<span class="keyword">lambda</span> x :x.split(<span class="string">' '</span>)[<span class="number">0</span>])</span><br><span class="line">    datas_copy = datas_copy[~datas_copy[<span class="string">'工资'</span>].str.contains(<span class="string">'天'</span>)] <span class="comment"># 除去实习的数据</span></span><br><span class="line">    datas_copy = datas_copy[~datas_copy[<span class="string">'工资'</span>].isna()] <span class="comment"># 除去工资为空的值</span></span><br><span class="line">    datas_copy[<span class="string">'工资'</span>] = datas_copy[<span class="string">'工资'</span>].apply(<span class="keyword">lambda</span> x :deal_salary(x))</span><br><span class="line">    grouped_city_salary = datas_copy[<span class="string">'工资'</span>].groupby(datas_copy[<span class="string">'工作地点'</span>])</span><br><span class="line">    salary_month = grouped_city_salary.agg([<span class="string">'mean'</span>]) <span class="comment">#计算各个城市的平均工资</span></span><br><span class="line">    salary_month.reset_index(inplace = <span class="literal">True</span>)</span><br><span class="line">    attr = []</span><br><span class="line">    value = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(salary_month.shape[<span class="number">0</span>]):</span><br><span class="line">        attr.append(salary_month[<span class="string">'工作地点'</span>][i])</span><br><span class="line">        value.append(str(salary_month[<span class="string">'mean'</span>][i])) <span class="comment">#将 int 数字转化为 string才能显示图片</span></span><br><span class="line">    bar = (</span><br><span class="line">        Bar()</span><br><span class="line">        .add_xaxis(attr)</span><br><span class="line">        .add_yaxis(<span class="string">"工资(元)"</span>,value)</span><br><span class="line">        .set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"城市平均工资统计图"</span>))</span><br><span class="line">        .set_series_opts(</span><br><span class="line">            label_opts=opts.LabelOpts(is_show=<span class="literal">False</span>),</span><br><span class="line">            markline_opts=opts.MarkLineOpts(</span><br><span class="line">                data=[</span><br><span class="line">                    opts.MarkLineItem(type_=<span class="string">"average"</span>, name=<span class="string">"平均值"</span>)</span><br><span class="line">                ]</span><br><span class="line">            ),</span><br><span class="line">            markpoint_opts=opts.MarkPointOpts(</span><br><span class="line">                data=[</span><br><span class="line">                    opts.MarkPointItem(type_=<span class="string">"max"</span>, name=<span class="string">"最大值"</span>),</span><br><span class="line">                    opts.MarkPointItem(type_=<span class="string">"min"</span>, name=<span class="string">"最小值"</span>),</span><br><span class="line">                ]</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> bar</span><br><span class="line"></span><br><span class="line">city_mean_salary = city_salary()</span><br><span class="line">city_mean_salary.render()</span><br><span class="line"><span class="comment">#make_snapshot(snapshot, city_mean_salary.render(), "城市平均工资统计图.png") # 使用此语句可直接生成图片</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="2-3-学历、工作经验要求"><a href="#2-3-学历、工作经验要求" class="headerlink" title="2.3 学历、工作经验要求"></a>2.3 学历、工作经验要求</h3><p>  你可能会问这些岗位这么好，会对学历有很高的要求吗？（学历在不同行业都是越高越好吗？）对工作经验又有什么样的要求呢？那么我们就通过数据来看一下结果吧，通过对所获取信息中的学历要求、工作经验进行统计，绘制“自动驾驶”职位学历要求饼图、工作经验要求饼图如图2-4和图2-5所示。</p>
<img title="图2-4  “自动驾驶”职位学历要求" data-src="/2019/10/17/BOSS直聘爬虫/图2-4%20%20“自动驾驶”职位学历要求.png">
<center>图2-4  “自动驾驶”职位学历要求</center>

<img title="图2-5  “自动驾驶”职位工作经验要求" data-src="/2019/10/17/BOSS直聘爬虫/图2-5%20%20“自动驾驶”职位工作经验要求.png">
<center>图2-5  “自动驾驶”职位工作经验要求</center>

<p>  通过统计结果可以看出，在获取的岗位招聘信息中，自动驾驶相关岗位对学历的要求不是很高，本科学历要求占75%以上，硕士学历要求占15%左右。结合经验要求来看，大部分的公司要求是经验不限和1-5年，这几个时间范围占了主要部分，所以结合这两个信息，认为“自动驾驶”岗位更加看重工作经验，只要有本科的学历，经验丰富能力强就可以找到不错的工作。</p>
<p>代码实现</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Page, Pie</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> pyecharts.render <span class="keyword">import</span> make_snapshot</span><br><span class="line"><span class="keyword">from</span> snapshot_selenium <span class="keyword">import</span> snapshot</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">edu_require</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">	学历要求饼图</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">    datas = pd.read_excel(<span class="string">'jobData.xls'</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">    datas_copy = datas</span><br><span class="line">    datas_copy = datas_copy[~datas_copy[<span class="string">'学历要求'</span>].str.contains(<span class="string">'个月'</span>)]   <span class="comment"># 去掉实习工作</span></span><br><span class="line">    grouped_eductaion = datas_copy.groupby(datas_copy[<span class="string">'学历要求'</span>]) <span class="comment"># 按学历分组</span></span><br><span class="line">    grouped_eductaion_count = grouped_eductaion[<span class="string">'学历要求'</span>].agg([<span class="string">'count'</span>]) <span class="comment"># 统计不同分组的数量</span></span><br><span class="line">    grouped_eductaion_count.reset_index(inplace = <span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># edu_data = [(grouped_eductaion_count['学历要求'][i], grouped_eductaion_count['count'][i]) for i in range(grouped_eductaion_count.shape[0])]</span></span><br><span class="line">    attr = []</span><br><span class="line">    value = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(grouped_eductaion_count.shape[<span class="number">0</span>]):</span><br><span class="line">        attr.append(grouped_eductaion_count[<span class="string">'学历要求'</span>][i])</span><br><span class="line">        value.append(str(grouped_eductaion_count[<span class="string">'count'</span>][i])) <span class="comment">#将 int 数字转化为 string才能显示图片</span></span><br><span class="line">    pie = (</span><br><span class="line">        Pie()</span><br><span class="line">        .add(</span><br><span class="line">            <span class="string">""</span>,</span><br><span class="line">            [list(z) <span class="keyword">for</span> z <span class="keyword">in</span> zip(attr, value)],</span><br><span class="line">            radius=[<span class="string">"40%"</span>, <span class="string">"75%"</span>]</span><br><span class="line">        )</span><br><span class="line">        .set_global_opts(</span><br><span class="line">            title_opts=opts.TitleOpts(title=<span class="string">"学历要求"</span>),</span><br><span class="line">            legend_opts=opts.LegendOpts(</span><br><span class="line">                orient=<span class="string">"vertical"</span>, pos_top=<span class="string">"15%"</span>, pos_left=<span class="string">"2%"</span></span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        .set_series_opts(label_opts=opts.LabelOpts(formatter=<span class="string">"{b}: {c}"</span>))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> pie</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exp_require</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">	工作经验要求饼图</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">    datas = pd.read_excel(<span class="string">'jobData.xls'</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">    datas_copy = datas</span><br><span class="line">    datas_copy = datas_copy[~datas_copy[<span class="string">'工作经验要求'</span>].str.contains(<span class="string">'天/周'</span>)]   <span class="comment"># 去掉实习工作</span></span><br><span class="line">    grouped_exp = datas_copy.groupby(datas_copy[<span class="string">'工作经验要求'</span>]) <span class="comment"># 按工作经验分组</span></span><br><span class="line">    grouped_exp_count = grouped_exp[<span class="string">'工作经验要求'</span>].agg([<span class="string">'count'</span>]) <span class="comment"># 统计不同分组的数量</span></span><br><span class="line">    grouped_exp_count.reset_index(inplace = <span class="literal">True</span>)</span><br><span class="line">    attr = []</span><br><span class="line">    value = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(grouped_exp_count.shape[<span class="number">0</span>]):</span><br><span class="line">        attr.append(grouped_exp_count[<span class="string">'工作经验要求'</span>][i])</span><br><span class="line">        value.append(str(grouped_exp_count[<span class="string">'count'</span>][i])) <span class="comment">#将 int 数字转化为 string才能显示图片</span></span><br><span class="line">    pie = (</span><br><span class="line">        Pie()</span><br><span class="line">        .add(</span><br><span class="line">            <span class="string">""</span>,</span><br><span class="line">            [list(z) <span class="keyword">for</span> z <span class="keyword">in</span> zip(attr, value)],</span><br><span class="line">            radius=[<span class="string">"40%"</span>, <span class="string">"75%"</span>]</span><br><span class="line">        )</span><br><span class="line">        .set_global_opts(</span><br><span class="line">            title_opts=opts.TitleOpts(title=<span class="string">"工作经验要求"</span>),</span><br><span class="line">            legend_opts=opts.LegendOpts(</span><br><span class="line">                orient=<span class="string">"vertical"</span>, pos_top=<span class="string">"15%"</span>, pos_left=<span class="string">"2%"</span></span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        .set_series_opts(label_opts=opts.LabelOpts(formatter=<span class="string">"{b}: {c}"</span>))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> pie</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">edu_pie = edu_require()</span><br><span class="line">edu_pie.render(<span class="string">"学历要求饼图.html"</span>)</span><br><span class="line">exp_pie = exp_require()</span><br><span class="line">exp_pie.render(<span class="string">"工作经验要求饼图.html"</span>)</span><br><span class="line"><span class="comment">#make_snapshot(snapshot, edu_pie.render(), "学历要求饼图.png") # 使用此语句可直接生成图片</span></span><br><span class="line"><span class="comment">#make_snapshot(snapshot, exp_pie.render(), "工作经验要求饼图.png") # 使用此语句可直接生成图片</span></span><br></pre></td></tr></tbody></table></figure>
<h3 id="2-4-工作种类、主要企业、行业分布"><a href="#2-4-工作种类、主要企业、行业分布" class="headerlink" title="2.4 工作种类、主要企业、行业分布"></a>2.4 工作种类、主要企业、行业分布</h3><p>  分析完学历与工作经验，我们来分析一下这些工作主要包括哪些种类，也就是说“自动驾驶”的招聘岗位主要包括哪些，可以为求职者提供学习的方向。为了更好地展示数据分析的成果，我们使用了优秀的开源包<span class="exturl" data-url="aHR0cHM6Ly9weXBpLm9yZy9wcm9qZWN0L2ppZWJhLw==" title="https://pypi.org/project/jieba/">jieba<i class="fa fa-external-link"></i></span>以及强大、方便的可视化工具<span class="exturl" data-url="aHR0cHM6Ly9weXBpLm9yZy9wcm9qZWN0L3B5ZWNoYXJ0cy8=" title="https://pypi.org/project/pyecharts/">pyecharts<i class="fa fa-external-link"></i></span>展示，根据“工作名”这一项数据项先进行分词，然后绘制了词云如图2-6所示。</p>
<img title="图2-6  “自动驾驶”主要岗位种类分析" data-src="/2019/10/17/BOSS直聘爬虫/图2-6%20%20“自动驾驶”主要岗位种类分析.png">
<center>图2-6  “自动驾驶”主要岗位种类分析</center>

<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Page, WordCloud</span><br><span class="line"><span class="keyword">from</span> pyecharts.globals <span class="keyword">import</span> SymbolType</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">job_title</span><span class="params">()</span>:</span></span><br><span class="line">    datas = pd.read_excel(<span class="string">'jobData.xls'</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">    datas_copy = datas</span><br><span class="line">    text = <span class="string">''</span>.join(datas_copy[<span class="string">'岗位'</span>])</span><br><span class="line">    requirements = [word <span class="keyword">for</span> word <span class="keyword">in</span> jieba.cut(text, cut_all=<span class="literal">True</span>)] <span class="comment"># 全模式分词</span></span><br><span class="line">    requirements_top = Counter(requirements)  <span class="comment"># Counter()函数对str进行统计</span></span><br><span class="line">    requirements_top50 = requirements_top.most_common(<span class="number">50</span>)    <span class="comment"># 统计最多的50个 ，most_common返回(string , count)的数据形式</span></span><br><span class="line">    c = (</span><br><span class="line">        WordCloud()</span><br><span class="line">        .add(<span class="string">""</span>, requirements_top50, word_size_range=[<span class="number">20</span>, <span class="number">100</span>], shape=SymbolType.DIAMOND)</span><br><span class="line">        .set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"主要岗位名称"</span>))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line">job_title = job_title()</span><br><span class="line">job_title.render(<span class="string">"主要岗位名称.html"</span>)</span><br></pre></td></tr></tbody></table></figure>
<p>  从图中可以看出，<code>算法</code>、<code>规划</code>、<code>感知</code>、<code>控制</code>、<code>嵌入式</code>等关键词频率较高，所以想要从事这一领域的工作，可以多多关注和学习这些领域的知识。为以后的求职做好准备，打下基础。<br>  那么哪些公司是招聘的大户呢？即招聘岗位数量较多的企业有哪些？我们使用同样的方法绘制了基于企业招聘数量的词云如图2-7所示。</p>
<img title="图2-7  “自动驾驶”主要招聘企业" data-src="/2019/10/17/BOSS直聘爬虫/图2-7%20%20“自动驾驶”主要招聘企业.png">
<center>图2-7  “自动驾驶”主要招聘企业</center>

<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Page, WordCloud</span><br><span class="line"><span class="keyword">from</span> pyecharts.globals <span class="keyword">import</span> SymbolType</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">company_count</span><span class="params">()</span>:</span></span><br><span class="line">    datas = pd.read_excel(<span class="string">'jobData.xls'</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">    datas_copy = datas</span><br><span class="line">    grouped_company = datas_copy.groupby(datas_copy[<span class="string">'招聘公司'</span>]) <span class="comment"># 按招聘公司分组</span></span><br><span class="line">    grouped_company_count = grouped_company[<span class="string">'招聘公司'</span>].agg([<span class="string">'count'</span>]) <span class="comment"># 统计不同分组的数量</span></span><br><span class="line">    grouped_company_count.reset_index(inplace = <span class="literal">True</span>)</span><br><span class="line">    company_data = [(grouped_company_count[<span class="string">'招聘公司'</span>][i],str(grouped_company_count[<span class="string">'count'</span>][i])) \</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(grouped_company_count.shape[<span class="number">0</span>])]</span><br><span class="line">    <span class="comment"># 是否要将数字转化为str</span></span><br><span class="line"></span><br><span class="line">    c = (</span><br><span class="line">        WordCloud()</span><br><span class="line">        .add(<span class="string">""</span>, company_data, word_size_range=[<span class="number">20</span>, <span class="number">100</span>], shape=SymbolType.DIAMOND)</span><br><span class="line">        .set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"主要的招聘公司"</span>))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line">company_count = company_count()</span><br><span class="line">company_count.render(<span class="string">"主要的招聘公司.html"</span>)</span><br><span class="line"><span class="comment">#make_snapshot(snapshot, company_count.render(), "主要的招聘公司.png") # 使用此语句可直接生成图片</span></span><br></pre></td></tr></tbody></table></figure>
<p>  可以看出，招聘数量排在前几位的分别有禾多科技、<span class="exturl" data-url="aHR0cHM6Ly93d3cuZGVlcGJsdWVhaS5jb20=" title="https://www.deepblueai.com">深兰科技<i class="fa fa-external-link"></i></span>、<span class="exturl" data-url="aHR0cHM6Ly93d3cuY3Rpcm9ib3QuY29t" title="https://www.ctirobot.com">坎德拉<i class="fa fa-external-link"></i></span>、<span class="exturl" data-url="aHR0cDovL3d3dy41MWhpdGVjaC5jb20=" title="http://www.51hitech.com">51VR<i class="fa fa-external-link"></i></span>、<span class="exturl" data-url="aHR0cDovL3d3dy5rb3RlaS5jb20uY24=" title="http://www.kotei.com.cn">武汉光庭科技<i class="fa fa-external-link"></i></span>、<span class="exturl" data-url="aHR0cDovL3d3dy55aWhhbmcuYWk=" title="http://www.yihang.ai">易航<i class="fa fa-external-link"></i></span>等公司，互联网大厂腾讯、华为，传统车厂吉利集团紧随其后，还有很多年轻的企业也有上榜。</p>
<p>  这些岗位所属的行业又有哪些呢？我们使用同样的方法统计如图2-8所示。</p>
<img title="图2-8  自动驾驶招聘行业分布" data-src="/2019/10/17/BOSS直聘爬虫/图2-8%20%20自动驾驶招聘行业分布.png">
<center>图2-8  自动驾驶招聘行业分布</center>

<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Page, WordCloud</span><br><span class="line"><span class="keyword">from</span> pyecharts.globals <span class="keyword">import</span> SymbolType</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">industry</span><span class="params">()</span>:</span></span><br><span class="line">    datas = pd.read_excel(<span class="string">'jobData.xls'</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">    datas_copy = datas</span><br><span class="line">    grouped_industry = datas_copy.groupby(datas_copy[<span class="string">'所属行业'</span>]) <span class="comment"># 按所属行业分组</span></span><br><span class="line">    grouped_industry_count = grouped_industry[<span class="string">'所属行业'</span>].agg([<span class="string">'count'</span>]) <span class="comment"># 统计不同分组的数量</span></span><br><span class="line">    grouped_industry_count.reset_index(inplace = <span class="literal">True</span>)</span><br><span class="line">    industry_data = [(grouped_industry_count[<span class="string">'所属行业'</span>][i],str(grouped_industry_count[<span class="string">'count'</span>][i])) \</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(grouped_industry_count.shape[<span class="number">0</span>])]</span><br><span class="line">    c = (</span><br><span class="line">        WordCloud()</span><br><span class="line">        .add(<span class="string">""</span>, industry_data, word_size_range=[<span class="number">20</span>, <span class="number">100</span>], shape=SymbolType.DIAMOND)</span><br><span class="line">        .set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"自动驾驶岗位行业分布"</span>))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line">industry_distribution = industry()</span><br><span class="line">industry_distribution.render(<span class="string">"自动驾驶岗位行业分布.html"</span>)</span><br><span class="line"><span class="comment">#make_snapshot(snapshot, industry_distribution.render(), "自动驾驶岗位行业分布.png") # 使用此语句可直接生成图片</span></span><br></pre></td></tr></tbody></table></figure>
<p>  从图中可以看出现在“自动驾驶”的企业所示行业多为“计算机互联网”、“智能硬件”以及“汽车生产”行业，这三类行业是招聘的主力军。</p>
<h2 id="三、总结与讨论"><a href="#三、总结与讨论" class="headerlink" title="三、总结与讨论"></a>三、总结与讨论</h2><h3 id="3-1-总结"><a href="#3-1-总结" class="headerlink" title="3.1 总结"></a>3.1 总结</h3><p>从两个方面进行总结，</p>
<ul>
<li><p>首先是内容上：从数据的分析中对于<strong>自动驾驶</strong>岗位的招聘需求有了进一步的认识，自动驾驶相关岗位主要的工作内容有<strong>算法、规划、感知、控制、嵌入式</strong>，北京、江浙沪（包邮区）和深圳是主要的工作地点，全国范围内的平均薪资为18422元/月，自动驾驶岗位更加看重工作经验、学历多数要求为本科，所在行业一般为<strong>计算机互联网、智能硬件以及汽车生产</strong>，招聘需求较多的企业有禾多科技、深兰科技、坎德拉、51VR、武汉光庭科技、易航等公司。</p>
</li>
<li><p>其次是技术上总结：<br>在数据获取中学会使用开发者工具发现网页规律；在数据解析中学会使用<code>xpath</code>、<code>beautifulSoup</code>；数据分析中学会使用<code>pyecharts</code>绘制多种有趣的可视化图片，学会使用<code>jieba</code>包统计词频。</p>
</li>
</ul>
<h3 id="3-2-遇到的问题"><a href="#3-2-遇到的问题" class="headerlink" title="3.2 遇到的问题"></a>3.2 遇到的问题</h3><p>  本文一开始想要获取更详细的<code>工作职责</code>和<code>工作技能要求</code>的数据，在爬取详情页的过程中发现BOSS直聘在请求详情页时每次的请求都会产生不同的<code>cookie</code>，否则无法获取想要的html，会跳转到其他页面，经过google查询已经有前辈发现了这个问题，但是还未找到解决的反反爬方法（魔高一尺道高一丈）。所以改为爬取较为容易获取的详情页面。</p>
<h3 id="3-3-不足之处"><a href="#3-3-不足之处" class="headerlink" title="3.3 不足之处"></a>3.3 不足之处</h3><p>  本文仅仅分析了BOSS直聘一家的数据，数据来源与实际情况有一定的差别，但是能体现一定的代表性，未来可以进行多家招聘网站（如<strong>智联招聘、51job招聘，前程无忧</strong>等）的数据爬取，提高数据的可信度。</p>
<h3 id="3-4-未来工作"><a href="#3-4-未来工作" class="headerlink" title="3.4 未来工作"></a>3.4 未来工作</h3><p>  目前已经完成数据的<code>获取、分析、统计、可视化</code>，未来还可以对数据之间的<code>相关性</code>进行<code>建模分析</code>，得出有意思、有价值的结论。（例如，哪些数据对薪资有影响？）</p>
<h3 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h3><p>  <em>本文的主要方法与技术代码参考了网络上的博客，在此一并致谢！</em></p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]    LI D, MEI H, YI S, et al. ECharts: A declarative framework for rapid construction of web-based visualization ☆ [J]. Visual Informatics, 2018, S2468502X18300068-.</p>
<p>[2] <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjkzNzU4L2FydGljbGUvZGV0YWlscy84ODU3MzM2MA==" title="https://blog.csdn.net/qq_42293758/article/details/88573360">Python爬取岗位数据并分析<i class="fa fa-external-link"></i></span></p>
<p>[3] <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzMDY5NC9hcnRpY2xlL2RldGFpbHMvOTY2NTAyODE=" title="https://blog.csdn.net/weixin_43930694/article/details/96650281">Python3 + xpath + excel 实现对boss直聘网的爬取<i class="fa fa-external-link"></i></span></p>
<p>[4] <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI3NjY4MzEzL2FydGljbGUvZGV0YWlscy84MjkyNDYyMg==" title="https://blog.csdn.net/qq_27668313/article/details/82924622">BOSS直聘网站数据分析岗位信息爬取<i class="fa fa-external-link"></i></span></p>
<script>
        document.querySelectorAll('.github-emoji')
          .forEach(el => {
            if (!el.dataset.src) { return; }
            const img = document.createElement('img');
            img.style = 'display:none !important;';
            img.src = el.dataset.src;
            img.addEventListener('error', () => {
              img.remove();
              el.style.color = 'inherit';
              el.style.backgroundImage = 'none';
              el.style.background = 'none';
            });
            img.addEventListener('load', () => {
              img.remove();
            });
            document.body.appendChild(img);
          });
      </script>
    </div>

    
    
    
      
<div class="post-widgets">
      <div id="needsharebutton-postbottom">
        <span class="btn">
          <i class="fa fa-share-alt" aria-hidden="true"></i>
        </span>
      </div>
    </div>
        
      
        <div class="reward-container">
  <div></div>
  <button disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
        
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.png" alt="CaoXu 微信支付">
        <p>微信支付</p>
      </div>
        
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="CaoXu 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>

      
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>CaoXu
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://www.caoxu.club/2019/10/17/BOSS直聘爬虫/" title="BOSS直聘“自动驾驶”岗位信息爬取与分析">http://www.caoxu.club/2019/10/17/BOSS直聘爬虫/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/python/" rel="tag"><i class="fa fa-tag"></i> python</a>
            
              <a href="/tags/爬虫/" rel="tag"><i class="fa fa-tag"></i> 爬虫</a>
            
              <a href="/tags/工作信息/" rel="tag"><i class="fa fa-tag"></i> 工作信息</a>
            
              <a href="/tags/可视化/" rel="tag"><i class="fa fa-tag"></i> 可视化</a>
            
              <a href="/tags/pyecharts/" rel="tag"><i class="fa fa-tag"></i> pyecharts</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2019/10/12/hello-world/" rel="next" title="Hello World">
                  <i class="fa fa-chevron-left"></i> Hello World
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2019/11/07/逻辑回归模型/" rel="prev" title="R语言|逻辑回归模型建模案例（交通事故预测）">
                  R语言|逻辑回归模型建模案例（交通事故预测） <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
    
  <div class="comments" id="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC80NzA3Ni8yMzU3Ng=="></div>
  </div>
  
  

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#一、数据爬取"><span class="nav-text">一、数据爬取</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-分析目标页，构造URL"><span class="nav-text">1.1 分析目标页，构造URL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-爬取、解析数据并保存"><span class="nav-text">1.2 爬取、解析数据并保存</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-1-确定要爬取的信息"><span class="nav-text">1.2.1 确定要爬取的信息</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#1-2-2-发送请求、解析数据、保存数据"><span class="nav-text">1.2.2 发送请求、解析数据、保存数据</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二、数据分析"><span class="nav-text">二、数据分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-工作地点全国分布"><span class="nav-text">2.1 工作地点全国分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-薪资水平"><span class="nav-text">2.2 薪资水平</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-学历、工作经验要求"><span class="nav-text">2.3 学历、工作经验要求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-工作种类、主要企业、行业分布"><span class="nav-text">2.4 工作种类、主要企业、行业分布</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三、总结与讨论"><span class="nav-text">三、总结与讨论</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-总结"><span class="nav-text">3.1 总结</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-遇到的问题"><span class="nav-text">3.2 遇到的问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-不足之处"><span class="nav-text">3.3 不足之处</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-未来工作"><span class="nav-text">3.4 未来工作</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#致谢"><span class="nav-text">致谢</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考文献"><span class="nav-text">参考文献</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/android-chrome-512x512.png"
      alt="CaoXu">
  <p class="site-author-name" itemprop="name">CaoXu</p>
  <div class="site-description" itemprop="description">记录在技术学习道路上的点点滴滴，分享有趣的项目经验</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">18</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2Nhby14dQ==" title="GitHub &rarr; https://github.com/cao-xu"><i class="fa fa-fw fa-github"></i>GitHub</span>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <span class="exturl" data-url="bWFpbHRvOnh1Y2FvMTEzMEAxNjMuY29t" title="E-Mail &rarr; mailto:xucao1130@163.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</span>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <span class="exturl" data-url="aHR0cHM6Ly93ZWliby5jb20vdS8yNjAwNDU3MzIx" title="Weibo &rarr; https://weibo.com/u/2600457321"><i class="fa fa-fw fa-weibo"></i>Weibo</span>
      </span>
    
  </div>
  <div class="cc-license motion-element" itemprop="license">
    
  
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC8="><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      友情链接
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cHM6Ly9hcnRobGlhbnQuZ2l0aHViLmlv" title="https://arthliant.github.io">斜阳草树</span>
        </li>
      
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cDovL3d3dy56MTYzODgudG9w" title="http://www.z16388.top">崎径其镜</span>
        </li>
      
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cHM6Ly8wdG9wLmdpdGh1Yi5pbw==" title="https://0top.github.io">zerotop</span>
        </li>
      
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cHM6Ly9zZWFpaS1ibG9nLmNvbQ==" title="https://seaii-blog.com">Seaii's Blog</span>
        </li>
      
    </ul>
  </div>

      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">CaoXu</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    
    <span title="站点总字数">66k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    
    <span title="站点阅读时长">1:01</span>
</div>

        
<div class="busuanzi-count">
  <script pjax async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
  
    <span class="post-meta-divider">|</span>
  
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
  
</div>












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/pjax/pjax.min.js?v=0.2.8"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1/dist/medium-zoom.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.1"></script><script src="/js/motion.js?v=7.4.1"></script>
<script src="/js/schemes/muse.js?v=7.4.1"></script>

<script src="/js/next-boot.js?v=7.4.1"></script>
  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.getAttribute('pjax') !== null) {
      element.setAttribute('pjax', '');
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  
  <script pjax>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>








  <script src="/js/local-search.js?v=7.4.1"></script>













    <div id="pjax">

  

  

  

  

<script>
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
</script>

  <script src="//cdn.jsdelivr.net/gh/theme-next/theme-next-needmoreshare2@1/needsharebutton.min.js"></script>
  <script>
      pbOptions = {};
        pbOptions.iconStyle = "box";
      
        pbOptions.boxForm = "horizontal";
      
        pbOptions.position = "bottomCenter";
      
        pbOptions.networks = "Weibo,Wechat,Douban,QQZone,Twitter,Facebook";
      
      new needShareButton('#needsharebutton-postbottom', pbOptions);
  </script>
    </div>
<script async>window.onload=function(){var a=document.createElement('script'),b=document.getElementsByTagName('script')[0];a.type='text/javascript',a.async=!0,a.src='/sw-register.js?v='+Date.now(),b.parentNode.insertBefore(a,b)};</script></body></html>