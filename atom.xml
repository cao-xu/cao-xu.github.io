<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>CaoXu&#39;s Blog</title>
  
  <subtitle>想法、创意与实践</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.caoxu.club/"/>
  <updated>2019-11-07T12:46:14.138Z</updated>
  <id>http://www.caoxu.club/</id>
  
  <author>
    <name>CaoXu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>R语言|逻辑回归模型建模案例（交通事故预测）</title>
    <link href="http://www.caoxu.club/2019/11/07/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/"/>
    <id>http://www.caoxu.club/2019/11/07/逻辑回归模型/</id>
    <published>2019-11-07T02:35:20.000Z</published>
    <updated>2019-11-07T12:46:14.138Z</updated>
    
    <content type="html"><![CDATA[<blockquote class="blockquote-center"><p><em>所有的模型都是错的，但是有用 <span class="github-emoji" style="color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png?v8">🌟</span></em></p></blockquote><img title="拟合ROC" data-src="/2019/11/07/逻辑回归模型/拟合ROC.png"><p>本介绍如何建立逻辑回归模型进行交通事故预测，并验证了模型的准确度。<br><a id="more"></a></p><div class="note default">            <h2 id="一、问题描述与数据准备"><a href="#一、问题描述与数据准备" class="headerlink" title="一、问题描述与数据准备"></a>一、问题描述与数据准备</h2>          </div><h3 id="1-1-问题描述"><a href="#1-1-问题描述" class="headerlink" title="1.1 问题描述"></a>1.1 问题描述</h3><p>  基于交通事故相关数据，建立逻辑回归模型，并尽可能使模型的预测准确度达到最高。<br>  使用交通事故发生前的车辆速度变化值、道路流量的变化值和天气的类型（下雨/晴天），建立回归模型对是否发生交通事故（事故/非事故）进行预测。</p><h3 id="1-2-数据导入与类型转换"><a href="#1-2-数据导入与类型转换" class="headerlink" title="1.2 数据导入与类型转换"></a>1.2 数据导入与类型转换</h3><h4 id="1-2-1-数据读取"><a href="#1-2-1-数据读取" class="headerlink" title="1.2.1 数据读取"></a>1.2.1 数据读取</h4><p>原始数据可通过百度网盘下载：<span class="exturl" data-url="aHR0cHM6Ly9wYW4uYmFpZHUuY29tL3MvMXRlVk1pWU9hYUhqRVhsRFg1MjBNY3cg" title="https://pan.baidu.com/s/1teVMiYOaaHjEXlDX520Mcw "><i class="fa fa-download fa-fw"></i>数据下载<i class="fa fa-external-link"></i></span></p><p>使用<code>read.csv（）</code>函数读取CSV格式数据</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">SourceData &lt;- read.csv(<span class="string">"C:/Users/Fred/R_project/GLM_dataModel/data 1.csv"</span>)</span><br></pre></td></tr></tbody></table></figure><h4 id="1-2-2-数据类型转化"><a href="#1-2-2-数据类型转化" class="headerlink" title="1.2.2 数据类型转化"></a>1.2.2 数据类型转化</h4><p>原始数据类型如下表所示，需要将<code>case</code>和<code>weather</code>均转换为无序因子型的数据。</p><center>表1-1  原始数据分析</center><div class="table-container"><table><thead><tr><th><center>变量名</center></th><th><center>数据类型</center></th><th><center>变量描述</center></th></tr></thead><tbody><tr><td><center>case</center></td><td><center>int</center></td><td><center>是否发生事故，1：事故，0：非事故</center></td></tr><tr><td><center>spd_dif_1min</center></td><td><center> Num</center></td><td><center>事故发生前0-1分钟内的速度变化值</center></td></tr><tr><td><center>spd_dif_2min</center></td><td><center> Num</center></td><td><center>事故发生前1-2分钟内的速度变化值</center></td></tr><tr><td><center>spd_dif_3min</center></td><td><center> Num</center></td><td><center>事故发生前2-3分钟内的速度变化值</center></td></tr><tr><td><center>spd_dif_4min</center></td><td><center>Num</center></td><td><center>事故发生前3-4分钟内的速度变化值</center></td></tr><tr><td><center>vol_dif_1min</center></td><td><center>Num</center></td><td><center>事故发生前0-1分钟内的流量变化值</center></td></tr><tr><td><center>vol_dif_2min</center></td><td><center>Num</center></td><td><center>事故发生前1-2分钟内的流量变化值</center></td></tr><tr><td><center>vol_dif_3min</center></td><td><center> Num</center></td><td><center>事故发生前2-3分钟内的流量变化值</center></td></tr><tr><td><center>vol_dif_4min</center></td><td><center> Num</center></td><td><center>事故发生前3-4分钟内的流量变化值</center></td></tr><tr><td><center>Weather</center></td><td><center>int</center></td><td><center>1（下雨），0（晴天）</center></td></tr></tbody></table></div><p>使用<code>factor（）</code>函数实现类型转换，代码实现如下。</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">## 将case、weather转换为因子型变量，表示类型</span></span><br><span class="line">nonNA_Data$case &lt;- factor(nonNA_Data$case,levels = c(<span class="number">0</span>,<span class="number">1</span>),labels = c(<span class="string">"非事故"</span>,<span class="string">"事故"</span>))</span><br><span class="line">nonNA_Data$Weather &lt;- factor(nonNA_Data$Weather,levels = c(<span class="number">0</span>,<span class="number">1</span>),labels = c(<span class="string">"晴天"</span>,<span class="string">"下雨"</span>))</span><br></pre></td></tr></tbody></table></figure><div class="note default">            <h2 id="二、数据预处理"><a href="#二、数据预处理" class="headerlink" title="二、数据预处理"></a>二、数据预处理</h2>          </div><h3 id="2-1-统计冗余数据"><a href="#2-1-统计冗余数据" class="headerlink" title="2.1 统计冗余数据"></a>2.1 统计冗余数据</h3><p>首先检查是否含有冗余数据，使用<code>duplicated（）</code>函数对原始数据进行判断，检查发现无重复数据。</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">  <span class="comment">##冗余数据处理</span></span><br><span class="line">duplicated_count &lt;- sum(duplicated(SourceData))<span class="comment"># 结果无重复数据</span></span><br></pre></td></tr></tbody></table></figure><h3 id="2-2-缺失值分析及处理"><a href="#2-2-缺失值分析及处理" class="headerlink" title="2.2 缺失值分析及处理"></a>2.2 缺失值分析及处理</h3><h4 id="2-2-1-缺失值分析"><a href="#2-2-1-缺失值分析" class="headerlink" title="2.2.1 缺失值分析"></a>2.2.1 缺失值分析</h4><p>在得到数据集后，我们需要观察数据的分布情况，因为很多的模型对缺失值敏感，因此观察是否有缺失值是其中很重要的一个步骤。在正式分析前，我们先通过图形进行对观测字段的缺失情况有一个直观的感受。</p><p>  使用<strong>VIM</strong>包中的<code>aggr（）</code>函数对缺失值进行图形探究。</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(<span class="string">"VIM"</span>)</span><br><span class="line">aggr(SourceData,prop=<span class="literal">FALSE</span>,numbers = <span class="literal">TRUE</span>)</span><br></pre></td></tr></tbody></table></figure><img title="aggr()生成的原始数据集的缺失值模式图形" data-src="/2019/11/07/逻辑回归模型/图2-1%20%20aggr()生成的原始数据集的缺失值模式图形.png"><center>图2-1  aggr()生成的原始数据集的缺失值模式图形</center><p><code>aggr()</code>函数不仅绘制每个变量的缺失值数，还绘制每个变量组合的缺失值数。红色表示缺失，不含缺失值的实例有759个，有缺失值的实例36个；可以看出前4分钟的速度变化值缺失值最多有11个。</p><p>使用<code>matrixplot()</code>函数可以生成每个实例数据的图形。</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">matrixplot(SourceData)</span><br></pre></td></tr></tbody></table></figure><img title="图2-2  原始数据集按实例（行）展示真实值和缺失值的矩阵图" data-src="/2019/11/07/逻辑回归模型/图2-2%20%20原始数据集按实例（行）展示真实值和缺失值的矩阵图.png"><center>图2-2  原始数据集按实例（行）展示真实值和缺失值的矩阵图</center><p>此处，数值型数据被重新转换到[0, 1]区间，并用灰度来表示大小：浅色表示值小，深色表示值大。默认缺失值为红色</p><h4 id="2-2-2-缺失值插补"><a href="#2-2-2-缺失值插补" class="headerlink" title="2.2.2 缺失值插补"></a>2.2.2 缺失值插补</h4><p>对于缺失值的处理方法非常多，例如基于聚类的方法，基于回归的方法，基于均值的方法，其中最简单的方法是直接移除，但是在本文中因为缺失值所占比例较高，直接移除会损失大量观测，因此并不是最合适的方法。在这里，我们使用<code>KNN方法</code>对缺失值进行填补。</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">    <span class="comment">### 删除（异常值）case为空的记录</span></span><br><span class="line">nonNA_Data &lt;- SourceData[-which(is.na(SourceData$case)),]</span><br><span class="line">    <span class="comment">### 使用kNN方法对缺失值填补</span></span><br><span class="line">nonNA_Data &lt;- knnImputation(nonNA_Data,k=<span class="number">10</span>,meth = <span class="string">"weighAvg"</span>)</span><br></pre></td></tr></tbody></table></figure><h3 id="2-3-异常值分析及处理"><a href="#2-3-异常值分析及处理" class="headerlink" title="2.3 异常值分析及处理"></a>2.3 异常值分析及处理</h3><p>使用箱型图对各个单因素变量进行异常值的分析，结果如下，发现并无明显的异常值。</p><img title="图2-3  异常值分析" data-src="/2019/11/07/逻辑回归模型/图2-3%20%20异常值分析.png"><center>图2-3  异常值分析</center><div class="note default">            <h2 id="三、变量分析"><a href="#三、变量分析" class="headerlink" title="三、变量分析"></a>三、变量分析</h2>          </div><h3 id="3-1-单变量分析"><a href="#3-1-单变量分析" class="headerlink" title="3.1 单变量分析"></a>3.1 单变量分析</h3><p>主要分析各个变量的分布，使用<code>ggplot2</code>包中的<code>ggplot（）</code>函数绘制各变量的分布统计图如下图。为了简洁，只展示两个变量。</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(ggplot2)</span><br><span class="line">opar &lt;- par(no.readonly = <span class="literal">TRUE</span>)</span><br><span class="line">par(mfrow = c(<span class="number">2</span>,<span class="number">4</span>))</span><br><span class="line">ggplot(df.train, aes(x = spd_dif_1min, y = ..density..)) + geom_histogram(fill = <span class="string">"blue"</span>, colour = <span class="string">"grey60"</span>, size = <span class="number">0.2</span>, alpha = <span class="number">0.2</span>) + geom_density()</span><br><span class="line">ggplot(df.train, aes(x = spd_dif_2min, y = ..density..)) + geom_histogram(fill = <span class="string">"blue"</span>, colour = <span class="string">"grey60"</span>, size = <span class="number">0.2</span>, alpha = <span class="number">0.2</span>) + geom_density()</span><br></pre></td></tr></tbody></table></figure><img title="图3-1  变量分布统计图1" data-src="/2019/11/07/逻辑回归模型/图3-1%20%20变量分布统计图1.png"><img title="图3-1  变量分布统计图2" data-src="/2019/11/07/逻辑回归模型/图3-1%20%20变量分布统计图2.png"><center>图3-1  变量分布统计图</center><p>可以看出，各个变量的分布大致呈负指数分布。</p><h3 id="3-2-多变量之间的相关性分析"><a href="#3-2-多变量之间的相关性分析" class="headerlink" title="3.2 多变量之间的相关性分析"></a>3.2 多变量之间的相关性分析</h3><p>建模之前首先得检验变量之间的相关性，如果变量之间相关性显著，会影响模型的预测效果。下面通过<code>corrplot</code>函数，画出各变量之间，包括响应变量与自变量的相关性。由下图可以看出，各变量之间的相关性是非常小的。</p><img title="图3-2  变量之间的相关性分析" data-src="/2019/11/07/逻辑回归模型/图3-2%20%20变量之间的相关性分析.png"><center>图3-2  变量之间的相关性分析</center><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(corrplot)</span><br><span class="line">cor1&lt;-cor(nonNA_Data[,<span class="number">2</span>:<span class="number">9</span>])</span><br><span class="line">corrplot(cor1,method = <span class="string">"number"</span>)</span><br></pre></td></tr></tbody></table></figure><div class="note default">            <h2 id="四、Logistic回归建模"><a href="#四、Logistic回归建模" class="headerlink" title="四、Logistic回归建模"></a>四、Logistic回归建模</h2>          </div><h3 id="4-1-数据集分割"><a href="#4-1-数据集分割" class="headerlink" title="4.1 数据集分割"></a>4.1 数据集分割</h3><p>将样本分为按照模型标定：模型校验=7:3的比例划分。<code>nrow（x）</code>返回x对象的序号，<code>Sample（）</code>函数随机抽取70%的序号，由此完成数据分割。</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train &lt;- sample(nrow(nonNA_Data), <span class="number">0.7</span>*nrow(nonNA_Data))</span><br><span class="line">  <span class="comment">## 表示从数据集中随机抽取70%的数据的序号</span></span><br><span class="line">df.train &lt;- nonNA_Data[train,]</span><br><span class="line">df.validate &lt;- nonNA_Data[-train,]</span><br></pre></td></tr></tbody></table></figure><h3 id="4-2-建立模型"><a href="#4-2-建立模型" class="headerlink" title="4.2 建立模型"></a>4.2 建立模型</h3><p>首先将所有自变量都考虑放入模型中，进行Logistic回归建模，模型如下。</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">fit.full &lt;- glm(case~spd_dif_1min + spd_dif_2min + spd_dif_3min + spd_dif_4m</span><br><span class="line"><span class="keyword">in</span> + vol_dif_1min + vol_dif_2min + vol_dif_3min + vol_dif_4min + Weather, da</span><br><span class="line">ta = df.train, family = binomial(link = <span class="string">'logit'</span>))</span><br><span class="line"> summary(fit.full)</span><br><span class="line"> <span class="comment">## Call:</span></span><br><span class="line"> <span class="comment">## glm(formula = case ~ spd_dif_1min + spd_dif_2min + spd_dif_3min +</span></span><br><span class="line"> <span class="comment">## spd_dif_4min + vol_dif_1min + vol_dif_2min + vol_dif_3min +</span></span><br><span class="line"> <span class="comment">## vol_dif_4min + Weather, family = binomial(link = "logit"),</span></span><br><span class="line"> <span class="comment">## data = df.train)</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">## Deviance Residuals:</span></span><br><span class="line"> <span class="comment">## Min 1Q Median 3Q Max</span></span><br><span class="line"> <span class="comment">## -1.6603 -0.6247 -0.4932 -0.4031 2.2398</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">## Coefficients:</span></span><br><span class="line"> <span class="comment">## Estimate Std. Error z value Pr(&gt;|z|)</span></span><br><span class="line"> <span class="comment">## (Intercept) -2.93342 0.27208 -10.781 &lt; 2e-16 ***</span></span><br><span class="line"> <span class="comment">## spd_dif_1min 0.13201 0.03045 4.335 1.46e-05 ***</span></span><br><span class="line"> <span class="comment">## spd_dif_2min 0.02350 0.04661 0.504 0.6141</span></span><br><span class="line"> <span class="comment">## spd_dif_3min 0.06076 0.04150 1.464 0.1431</span></span><br><span class="line"> <span class="comment">## spd_dif_4min 0.09812 0.04155 2.361 0.0182 *</span></span><br><span class="line"> <span class="comment">## vol_dif_1min 0.02697 0.01127 2.394 0.0167 *</span></span><br><span class="line"> <span class="comment">## vol_dif_2min 0.02265 0.01301 1.742 0.0815 .</span></span><br><span class="line"> <span class="comment">## vol_dif_3min 0.01161 0.01170 0.993 0.3209</span></span><br><span class="line"> <span class="comment">## vol_dif_4min 0.01010 0.01142 0.884 0.3767</span></span><br><span class="line"> <span class="comment">## Weather 下雨 0.15360 0.37075 0.414 0.6787</span></span><br><span class="line"> <span class="comment">## ---</span></span><br><span class="line"> <span class="comment">## Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">## (Dispersion parameter for binomial family taken to be 1)</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">## Null deviance: 544.17 on 554 degrees of freedom</span></span><br><span class="line"> <span class="comment">## Residual deviance: 487.01 on 545 degrees of freedom</span></span><br><span class="line"> <span class="comment">## AIC: 507.01</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">## Number of Fisher Scoring iterations: 4</span></span><br></pre></td></tr></tbody></table></figure><p>从<code>summary（）</code>返回的结果看出，自变量<code>spd_dif_1min</code>、<code>spd_dif_4min</code>和<code>vol_dif_1min</code>对方程的贡献度较为显著，而其他变量对方程的贡献度不显著，去除这些变量，检验新模型是否拟合得好：</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">fit.reduced &lt;- glm(case ~ spd_dif_1min + spd_dif_4min + vol_dif_1min, data =</span><br><span class="line">df.train, family = binomial(link = <span class="string">'logit'</span>))</span><br><span class="line"> summary(fit.reduced)</span><br><span class="line"></span><br><span class="line"> <span class="comment">## Call:</span></span><br><span class="line"> <span class="comment">## glm(formula = case ~ spd_dif_1min + spd_dif_4min + vol_dif_1min,</span></span><br><span class="line"> <span class="comment">## family = binomial(link = "logit"), data = df.train)</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">## Deviance Residuals:</span></span><br><span class="line"> <span class="comment">## Min 1Q Median 3Q Max</span></span><br><span class="line"> <span class="comment">## -1.8244 -0.6018 -0.5241 -0.4484 2.1127</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">## Coefficients:</span></span><br><span class="line"> <span class="comment">## Estimate Std. Error z value Pr(&gt;|z|)</span></span><br><span class="line"> <span class="comment">## (Intercept) -2.44831 0.20239 -12.097 &lt; 2e-16 ***</span></span><br><span class="line"> <span class="comment">## spd_dif_1min 0.13722 0.02938 4.670 3.01e-06 ***</span></span><br><span class="line"> <span class="comment">## spd_dif_4min 0.12250 0.03863 3.171 0.00152 **</span></span><br><span class="line"> <span class="comment">## vol_dif_1min 0.03197 0.01114 2.871 0.00410 **</span></span><br><span class="line"> <span class="comment">## ---</span></span><br><span class="line"> <span class="comment">## Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">## (Dispersion parameter for binomial family taken to be 1)</span></span><br><span class="line"> <span class="comment">## Null deviance: 544.17 on 554 degrees of freedom</span></span><br><span class="line"> <span class="comment">## Residual deviance: 496.79 on 551 degrees of freedom</span></span><br><span class="line"> <span class="comment">## AIC: 504.79</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">## Number of Fisher Scoring iterations: 4</span></span><br></pre></td></tr></tbody></table></figure><p>新模型的每个回归系数都非常显著（<strong>p&lt;0.05</strong>）。由于两模型嵌套（<code>fit.reduced</code>是<code>fit.full</code>的一个子集），可以使用<code>anova()</code>函数对它们进行比较，对于广义线性回归，可用卡方检验。</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">anova(fit.reduced, fit.full, test = <span class="string">"Chisq"</span>)</span><br><span class="line"> <span class="comment">## Analysis of Deviance Table</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">## Model 1: case ~ spd_dif_1min + spd_dif_4min + vol_dif_1min</span></span><br><span class="line"> <span class="comment">## Model 2: case ~ spd_dif_1min + spd_dif_2min + spd_dif_3min + spd_dif_4min+</span></span><br><span class="line"> <span class="comment">## vol_dif_1min + vol_dif_2min + vol_dif_3min + vol_dif_4min +</span></span><br><span class="line"> <span class="comment">## Weather</span></span><br><span class="line"> <span class="comment">## Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)</span></span><br><span class="line"> <span class="comment">## 1 551 496.79</span></span><br><span class="line"> <span class="comment">## 2 545 487.01 6 9.7794 0.1343</span></span><br></pre></td></tr></tbody></table></figure><p>结果的卡方值不显著（<strong>p=0.1343</strong>），<strong>表明三个预测变量的新模型与九个完整预测变量的模型拟合程度一样好</strong>。添加其他6个变量不会显著提高方程的预测精度，因此可以依据更简单的模型进行解释。</p><p>解释模型参数：</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">exp(coef(fit.reduced))</span><br><span class="line"><span class="comment">## (Intercept) spd_dif_1min spd_dif_4min vol_dif_1min</span></span><br><span class="line"><span class="comment">## 0.08643927 1.14708542 1.13031911 1.03248943</span></span><br></pre></td></tr></tbody></table></figure><p>可以看到，1min内速度的变化量增加1个单位，事故发生的优势将乘以1.14708542，同理1min速度、2min流量的变化量增加一个单位，事故发生的优势将乘以1.13031911、1.03248943。</p><h3 id="4-3-判定标定模型的拟合优度"><a href="#4-3-判定标定模型的拟合优度" class="headerlink" title="4.3 判定标定模型的拟合优度"></a>4.3 判定标定模型的拟合优度</h3><p>  通常一个二值分类器可以通过ROC（Receiver Operating Characteristic）曲线和AUC值来评价优劣。</p><p>  很多二元分类器会产生一个概率预测值，而非仅仅是0-1预测值。我们可以使用某个阈值（例如0.5），以划分哪些预测为1，哪些预测为0。得到二元预测值后，可以构建一个混淆矩阵来评价二元分类器的预测效果。所有的训练数据都会落入这个矩阵中，而对角线上的数字代表了预测正确的数目，即true positive + true negative。同时可以相应算出TPR（真正率或称为敏感度）和TNR（真负率或称为特异度）。我们主观上希望这两个指标越大越好，但可惜二者是一个此消彼涨的关系。除了分类器的训练参数，阈值的选择，也会大大的影响TPR和TNR。有时可以根据具体问题和需要，来选择具体的阈值。</p><img title="TPR和TNR" data-src="/2019/11/07/逻辑回归模型/TPR和TNR.png"><p>首先使用训练数据集生成概率预测值：</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">library</span>(pROC)</span><br><span class="line"> pre &lt;- predict(fit.reduced,type=<span class="string">'response'</span>,df.train)</span><br></pre></td></tr></tbody></table></figure><p>需要特别注意的是：<code>type</code>一定要加，否则计算的最优阈值为负数</p><p>下面使用<code>pROC</code>包计算<code>fit.reduced</code>模型的拟合优度：</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">modelroc &lt;- roc(df.train$case,pre)</span><br><span class="line">plot(modelroc, print.auc=<span class="literal">TRUE</span>, auc.polygon=<span class="literal">TRUE</span>, </span><br><span class="line">     grid=c(<span class="number">0.1</span>, <span class="number">0.2</span>), grid.col=c(<span class="string">"green"</span>, <span class="string">"red"</span>),</span><br><span class="line">     max.auc.polygon=<span class="literal">TRUE</span>,</span><br><span class="line">     auc.polygon.col=<span class="string">"skyblue"</span>, print.thres=<span class="literal">TRUE</span>)</span><br></pre></td></tr></tbody></table></figure><img title="图4-1  拟合优度ROC" data-src="/2019/11/07/逻辑回归模型/图4-1%20%20拟合优度ROC.png"><center>图4-1  拟合优度ROC</center><p>从图中可以看出阈值为<code>0.142</code>时，对应的AUC（Area Under Curve）值为<code>0.762</code>大于0.7，区分能力可以接受，还有提高的空间。阈值为0.142，对应的敏感度和特异度分别为：<code>0.907</code>、<code>0.533</code>。</p><div class="note default">            <h2 id="五、评估模型的预测效果"><a href="#五、评估模型的预测效果" class="headerlink" title="五、评估模型的预测效果"></a>五、评估模型的预测效果</h2>          </div><p>基于测试集使用建立的模型计算预测值，与真值比较计算出预测的准确率：</p><figure class="highlight r"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 评估模型的预测效果</span></span><br><span class="line"> predict &lt;- predict(fit.reduced,type=<span class="string">'response'</span>,newdata=df.validate)</span><br><span class="line"> predict.results &lt;- ifelse( predict&gt; <span class="number">0.142</span>,<span class="string">"事故"</span>,<span class="string">"非事故"</span>)</span><br><span class="line"> <span class="comment">## 错误率</span></span><br><span class="line"> misClasificError &lt;- mean(predict.results != df.validate$case)</span><br><span class="line"> print(paste(<span class="string">'准确率'</span>,<span class="number">1</span>-misClasificError))</span><br></pre></td></tr></tbody></table></figure><p>计算的准确率为 <strong>0.62343</strong>，准确率不是很高<span class="github-emoji" style="color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f648.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f648.png?v8">🙈</span>，可以考虑重新设计模型的结构提高准确率。</p><div class="note success">            <h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>  通过这个案例对广义线性模型中的logistics回归模型有了初步的了解,练习了数据预处理（建模准备）、建立模型、评价模型的完整过程<span class="github-emoji" style="color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f60e.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f60e.png?v8">😎</span>。</p>          </div><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1] Kabacoff R , 卡巴科弗, Kabacoff, et al. <span class="exturl" data-url="aHR0cHM6Ly9wYW4uYmFpZHUuY29tL3MvMXpXdHE=" title="https://pan.baidu.com/s/1zWtq">R 语言实战<i class="fa fa-external-link"></i></span>[M]. 人民邮电出版社, 2013.</p><p>[2] <span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vbnhsZC9wLzYxNzA2OTAuaHRtbA==" title="https://www.cnblogs.com/nxld/p/6170690.html">如何在R语言中使用Logistic回归模型<i class="fa fa-external-link"></i></span></p><p>[3] <span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vTGl0dGxlQm9vay9wLzY4NDI5MjAuaHRtbA==" title="https://www.cnblogs.com/LittleBook/p/6842920.html">信用卡评分<i class="fa fa-external-link"></i></span></p><p>[4] <span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8zMDk4MjU1MQ==" title="https://zhuanlan.zhihu.com/p/30982551">logistic回归预测婚姻出轨|R语言<i class="fa fa-external-link"></i></span></p><center>留言区欢迎任何的建议与批评<span class="github-emoji" style="color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f4a1.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a1.png?v8">💡</span>~</center><center>如果你觉得这篇文章对你有用，欢迎分享、打赏哦<span class="github-emoji" style="color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/2615.png?v8) center/contain" data-src="https://github.githubassets.com/images/icons/emoji/unicode/2615.png?v8">☕</span>~</center><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;blockquote class=&quot;blockquote-center&quot;&gt;&lt;p&gt;&lt;em&gt;所有的模型都是错的，但是有用 &lt;span class=&quot;github-emoji&quot; style=&quot;color: transparent;background:no-repeat url(https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png?v8) center/contain&quot; data-src=&quot;https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png?v8&quot;&gt;🌟&lt;/span&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;img title=&quot;拟合ROC&quot; data-src=&quot;/2019/11/07/逻辑回归模型/拟合ROC.png&quot;&gt;
&lt;p&gt;本介绍如何建立逻辑回归模型进行交通事故预测，并验证了模型的准确度。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="2019秋《交通数据分析》" scheme="http://www.caoxu.club/categories/2019%E7%A7%8B%E3%80%8A%E4%BA%A4%E9%80%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%8B/"/>
    
      <category term="广义线性模型" scheme="http://www.caoxu.club/categories/2019%E7%A7%8B%E3%80%8A%E4%BA%A4%E9%80%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%8B/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="logistics回归模型" scheme="http://www.caoxu.club/categories/2019%E7%A7%8B%E3%80%8A%E4%BA%A4%E9%80%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%8B/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/logistics%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/"/>
    
    
      <category term="R" scheme="http://www.caoxu.club/tags/R/"/>
    
      <category term="广义线性模型" scheme="http://www.caoxu.club/tags/%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="logistic回归模型" scheme="http://www.caoxu.club/tags/logistic%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/"/>
    
      <category term="数据预处理" scheme="http://www.caoxu.club/tags/%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86/"/>
    
      <category term="拟合优度" scheme="http://www.caoxu.club/tags/%E6%8B%9F%E5%90%88%E4%BC%98%E5%BA%A6/"/>
    
  </entry>
  
  <entry>
    <title>BOSS直聘“自动驾驶”岗位信息爬取与分析</title>
    <link href="http://www.caoxu.club/2019/10/17/BOSS%E7%9B%B4%E8%81%98%E7%88%AC%E8%99%AB/"/>
    <id>http://www.caoxu.club/2019/10/17/BOSS直聘爬虫/</id>
    <published>2019-10-17T07:40:49.000Z</published>
    <updated>2019-10-21T01:49:46.160Z</updated>
    
    <content type="html"><![CDATA[<p>  这是我个人博客的第一篇文章，是全新的开始。希望未来在这里记录更多有趣的探索。</p><img title="自动驾驶岗位名称" data-src="/2019/10/17/BOSS直聘爬虫/岗位名称.jpg"><p>  自动驾驶随着人工智能技术的成熟，人才需求在不断增加，为了对我国自动驾驶人才需求进行了解，本文选择<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpcGluLmNvbQ==" title="https://www.zhipin.com">BOSS直聘<i class="fa fa-external-link"></i></span>招聘网站获取自动驾驶相关职位信息，分析数据，根据分析结果确定人才需求、为以后的学习制定计划。<br><a id="more"></a></p><p>本文开发环境：<span class="exturl" data-url="aHR0cHM6Ly93d3cucHl0aG9uLm9yZw==" title="https://www.python.org">python3.7<i class="fa fa-external-link"></i></span> 、<span class="exturl" data-url="aHR0cHM6Ly93d3cuYW5hY29uZGEuY29t" title="https://www.anaconda.com">anconda3<i class="fa fa-external-link"></i></span></p><h2 id="一、数据爬取"><a href="#一、数据爬取" class="headerlink" title="一、数据爬取"></a>一、数据爬取</h2><h3 id="1-1-分析目标页，构造URL"><a href="#1-1-分析目标页，构造URL" class="headerlink" title="1.1 分析目标页，构造URL"></a>1.1 分析目标页，构造URL</h3><p>  首先，进入网站输入关键字“自动驾驶”查询得到职位的列表页面，对目标页面的URL分析<code>https://www.zhipin.com/c101010100/?query=自动驾驶&amp;page=1&amp;ka=page-1</code>，发现关键的字段有：<code>query</code>、<code>page</code>分别代表了要查询的<strong>关键字</strong>和<strong>页面</strong>，<code>c101010100</code>代表了城市的编号，当选择了<strong>全国</strong>时编号为<code>c101010100</code>，所以通过控制这三个参数，实现对全国所有职位列表页的信息的爬取。</p><img title="目标页面" data-src="/2019/10/17/BOSS直聘爬虫/图1-1目标页面.png"><center>图1-1  目标页面</center><p>  其次，构建headers cookie，通过尝试发现爬取Boss直聘必须添加cookie，构建的请求头如下。</p><p><code>header = {         'User-Agent':            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36',         'Cookie':            '_uab_collina=156967238793885639512262；bannerClose_wanmeishijie=true; lastCity=101010100; _bl_uid=q5k7F1m8aOIjLLybtrIhbILink0X; __c=1570153169; __g=-;Hm_lvt_194df3105ad7148dcf2b98a91b5e727a=1569912508,1569985933,1570068443,1570153169;__l=l=%2Fwww.zhipin.com%2F&amp;r=&amp;friend_source=0&amp;friend_source=0;toUrl=https%3A%2F%2Fwww.zhipin.com%2Fjob_detail%2F%3Fquery%3D%25E8%2587%25AA%25E5%258A%25A8%25E9%25A9%25BE%25E9%25A9%25B6%26city%3D101020100%26industry%3D%26position%3D;__zp_stoken__=eaf4AHdTnnRrM4tosXCE%2FCPA2IBqs%2BoMIR%2FkL2KsnUmYiwLERJs40PPb8KIurKugecg3l0jmgV1zyN86oQkjtd81dw%3D%3D;Hm_lpvt_194df3105ad7148dcf2b98a91b5e727a=1570159163;__a=64007787.1569672388.1570068443.1570153169.178.6.23.172;__zp_sseed__=4qNlVc1nPWG9Y7G66QfbgtQFW6iSHevalYp+HzrGFH4=; __zp_sname__=9d9e2c78;__zp_sts__=1570159388399'        }</code></p><h3 id="1-2-爬取、解析数据并保存"><a href="#1-2-爬取、解析数据并保存" class="headerlink" title="1.2 爬取、解析数据并保存"></a>1.2 爬取、解析数据并保存</h3><h4 id="1-2-1-确定要爬取的信息"><a href="#1-2-1-确定要爬取的信息" class="headerlink" title="1.2.1 确定要爬取的信息"></a>1.2.1 确定要爬取的信息</h4><p>  F12打开开发者工具，审查网页元素，需要获取的信息包括“工作名、薪资、工作地点、工作经验、学历要求、企业名、企业所属行业”。</p><img title="目标页面" data-src="/2019/10/17/BOSS直聘爬虫/图1-2分析目标页面.png"><center>图1-2  分析目标页面</center><h4 id="1-2-2-发送请求、解析数据、保存数据"><a href="#1-2-2-发送请求、解析数据、保存数据" class="headerlink" title="1.2.2 发送请求、解析数据、保存数据"></a>1.2.2 发送请求、解析数据、保存数据</h4><p>  对目标页面发送请求后，解析返回的html并提取所需要的信息，这里主要用到的包有：<code>urllib</code>、<code>requests</code>、<code>BeautifulSoup</code>、<code>lxml</code>。函数的主要步骤为：</p><ul><li>第一步，请求目标页面html</li><li>第二步，使用<code>lxml</code>和<code>bs4</code>解析目标信息</li><li>第三步，随机等待几秒，防止ip被封</li></ul><p>循环完成对所有页面岗位信息的提取，当完成数据的解析后，将数据保存到Excel表格中。下面的代码实现上述发送请求、解析数据、保存数据步骤。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_detial</span><span class="params">(total_page_count)</span>:</span></span><br><span class="line">    <span class="comment">#循环所有页面，</span></span><br><span class="line">    <span class="comment">#第一步，构造URL获取html</span></span><br><span class="line">    <span class="comment">#第二步，使用bs4解析详情页的超链接，保存到数组中</span></span><br><span class="line">    key_words = <span class="string">"自动驾驶"</span></span><br><span class="line">    key = urllib.parse.quote(key_words) <span class="comment">#将中文进行转码</span></span><br><span class="line">    jobs_title_list = []</span><br><span class="line">    area_list = []</span><br><span class="line">    work_exp_list = []</span><br><span class="line">    edu_list = []</span><br><span class="line">    company_list = []</span><br><span class="line">    salary_list = []</span><br><span class="line">    industry_list = []</span><br><span class="line">    financing_stage_list = []</span><br><span class="line">    company_scale_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,total_page_count+<span class="number">1</span>):   <span class="comment">#查看页面有10页职位列表</span></span><br><span class="line">        print(<span class="string">"正在爬取第 %s 页列表页..."</span> % i)</span><br><span class="line">        url =<span class="string">'https://www.zhipin.com/c100010000/?query='</span>+key+<span class="string">'&amp;page='</span>+str(i)+<span class="string">'&amp;ka=page-'</span>+str(i)</span><br><span class="line">        <span class="comment">#获取每页的列表html</span></span><br><span class="line">        per_page_html = get_job_html(url) </span><br><span class="line">        <span class="comment">#解析提取详情页超的数据</span></span><br><span class="line">        jobs_title,area,work_exp,edu,company,salary,industry\</span><br><span class="line">            =  parse_job_detial(per_page_html) <span class="comment">#,company_scale,financing_stage</span></span><br><span class="line">        <span class="comment"># 将每页30个数据尾加到总的数组</span></span><br><span class="line">        jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list\</span><br><span class="line">            = append_job_detial(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list,\</span><br><span class="line">                jobs_title,area,work_exp,edu,company,salary,industry) </span><br><span class="line">        <span class="comment">#随机等待,防止封ip</span></span><br><span class="line">        span=round(random.random()*<span class="number">6</span>,<span class="number">1</span>)</span><br><span class="line">        time.sleep(span)</span><br><span class="line">    print(<span class="string">"爬取列表页完成！"</span>)</span><br><span class="line">    <span class="comment"># 将爬取的数据保存到Excel</span></span><br><span class="line">    jobs_data = list(zip(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list)) </span><br><span class="line">    jobs_data.insert(<span class="number">0</span>, (<span class="string">"岗位"</span>,<span class="string">"工作地点"</span>,<span class="string">"工作经验要求"</span>,<span class="string">"学历要求"</span>,<span class="string">"招聘公司"</span>,<span class="string">"工资"</span>,<span class="string">"所属行业"</span>))</span><br><span class="line">    save_to_excel(<span class="string">"jobData"</span>, <span class="string">"AutoDriving"</span>, jobs_data) <span class="comment">#fileName,SheetName,数据</span></span><br><span class="line">    print(<span class="string">"保存数据成功，打开jobData.xls查看"</span>)</span><br></pre></td></tr></tbody></table></figure><p>  <code>get_job_html(url)</code>函数实现请求目标<code>url</code>，代码实现如下。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_job_html</span><span class="params">(url)</span>:</span></span><br><span class="line">    header = {</span><br><span class="line">         <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'</span>,</span><br><span class="line">         <span class="string">'Cookie'</span>:<span class="string">'_uab_collina=156967238793885639512262; bannerClose_wanmeishijie=true; lastCity=101010100; _bl_uid=q5k7F1m8aOIjLLybtrIhbILink0X; __c=1570153169; __g=-; Hm_lvt_194df3105ad7148dcf2b98a91b5e727a=1569912508,1569985933,1570068443,1570153169; __l=l=%2Fwww.zhipin.com%2F&amp;r=&amp;friend_source=0&amp;friend_source=0; toUrl=https%3A%2F%2Fwww.zhipin.com%2Fjob_detail%2F%3Fquery%3D%25E8%2587%25AA%25E5%258A%25A8%25E9%25A9%25BE%25E9%25A9%25B6%26city%3D101020100%26industry%3D%26position%3D; __zp_stoken__=eaf4AHdTnnRrM4tosXCE%2FCPA2IBqs%2BoMIR%2FkL2KsnUmYiwLERJs40PPb8KIurKugecg3l0jmgV1zyN86oQkjtd81dw%3D%3D; Hm_lpvt_194df3105ad7148dcf2b98a91b5e727a=1570159163; __a=64007787.1569672388.1570068443.1570153169.178.6.23.172; __zp_sseed__=4qNlVc1nPWG9Y7G66QfbgtQFW6iSHevalYp+HzrGFH4=; __zp_sname__=9d9e2c78; __zp_sts__=1570159388399'</span></span><br><span class="line">         }</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        html = requests.get(url,headers = header)</span><br><span class="line">        <span class="keyword">if</span> html.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> html.text <span class="comment">#返回列表页的html</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">except</span> RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></tbody></table></figure><p>  获取到网页html后解析想要的数据，实现代码如下。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_job_detial</span><span class="params">(per_page_html)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> per_page_html==<span class="string">''</span> <span class="keyword">or</span> len(per_page_html)==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"未请求到列表页的html！"</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        jobs_title = []</span><br><span class="line">        area = []</span><br><span class="line">        work_exp = []</span><br><span class="line">        edu = []</span><br><span class="line">        company = []</span><br><span class="line">        salary = []</span><br><span class="line">        industry = []</span><br><span class="line">        financing_stage = []</span><br><span class="line">        company_scale = []</span><br><span class="line">        <span class="comment"># 初始化 标准化html</span></span><br><span class="line">        html = etree.HTML(per_page_html) </span><br><span class="line">        <span class="comment"># 工作名</span></span><br><span class="line">        jobs_title = html.xpath(<span class="string">'//div[@class="job-title"]/text()'</span>)</span><br><span class="line">        <span class="comment">#print(jobs_title)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment"># 工作地点</span></span><br><span class="line">        area = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[1]'</span>)</span><br><span class="line">        <span class="comment">#print(area)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#工作经验要求</span></span><br><span class="line">        work_exp = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[2]'</span>)</span><br><span class="line">        <span class="comment">#print(work_exp)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#学历要求</span></span><br><span class="line">        edu = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[3]'</span>)</span><br><span class="line">        <span class="comment">#print(edu)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#公司名</span></span><br><span class="line">        company = html.xpath(<span class="string">'//div[@class="company-text"]//a/text()'</span>)</span><br><span class="line">        <span class="comment">#print(company)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment"># 工资</span></span><br><span class="line">        salary = html.xpath(<span class="string">'//div[@class="info-primary"]//span[@class="red"]/text()'</span>)</span><br><span class="line">        <span class="comment">#print(salary)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#所属行业</span></span><br><span class="line">        industry = html.xpath(<span class="string">'//div[@class="info-company"]//p/text()[1]'</span>)</span><br><span class="line">        <span class="keyword">return</span> jobs_title,area,work_exp,edu,company,salary,industry</span><br></pre></td></tr></tbody></table></figure><p>  每次获取的是一页职位列表信息，需要将每次的数据尾加到总的数据<code>list</code>中，代码实现如下。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append_job_detial</span><span class="params">(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list,jobs_title,area,work_exp,edu,company,salary,industry)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i,info <span class="keyword">in</span> enumerate(jobs_title):</span><br><span class="line">        jobs_title_list.append(jobs_title[i])</span><br><span class="line">        area_list.append(area[i])</span><br><span class="line">        work_exp_list.append(work_exp[i])</span><br><span class="line">        edu_list.append(edu[i])</span><br><span class="line">        company_list.append(company[i])</span><br><span class="line">        salary_list.append(salary[i])</span><br><span class="line">        industry_list.append(industry[i])</span><br><span class="line">    <span class="keyword">return</span> jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list</span><br></pre></td></tr></tbody></table></figure><p>  当所有页面的数据获取解析完成后，将数据保存为Excel的形式，代码实现：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_excel</span><span class="params">(filename,sheet_name,data)</span>:</span></span><br><span class="line">    f = xlwt.Workbook(encoding=<span class="string">'utf-8'</span>)  <span class="comment">#创建一个Workbook 设置编码</span></span><br><span class="line">    <span class="comment"># 第二参数表示是否可以覆盖单元格 其实是 Workbook实例化的一个参数，默认值为False</span></span><br><span class="line">    sheet = f.add_sheet(sheet_name,cell_overwrite_ok=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，</span></span><br><span class="line">    <span class="comment"># 同时列出数据和数据下标，一般用在 for 循环当中。</span></span><br><span class="line">    <span class="keyword">for</span> row,row_data <span class="keyword">in</span> enumerate(data):  <span class="comment">#处理行</span></span><br><span class="line">        <span class="keyword">for</span> column,column_data <span class="keyword">in</span> enumerate(row_data): <span class="comment">#处理列</span></span><br><span class="line">            sheet.write(row,column,str(column_data))</span><br><span class="line">    f.save(filename + <span class="string">".xls"</span>)</span><br></pre></td></tr></tbody></table></figure><p>  对整个过程的代码集成如下。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree <span class="comment">#xpath</span></span><br><span class="line"><span class="keyword">from</span> requests.exceptions <span class="keyword">import</span> RequestException</span><br><span class="line"><span class="keyword">import</span> xlwt       <span class="comment">#excel操作</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_job_html</span><span class="params">(url)</span>:</span></span><br><span class="line">    header = {</span><br><span class="line">         <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'</span>,</span><br><span class="line">         <span class="string">'Cookie'</span>:<span class="string">'_uab_collina=156967238793885639512262; bannerClose_wanmeishijie=true; lastCity=101010100; _bl_uid=q5k7F1m8aOIjLLybtrIhbILink0X; __c=1570153169; __g=-; Hm_lvt_194df3105ad7148dcf2b98a91b5e727a=1569912508,1569985933,1570068443,1570153169; __l=l=%2Fwww.zhipin.com%2F&amp;r=&amp;friend_source=0&amp;friend_source=0; toUrl=https%3A%2F%2Fwww.zhipin.com%2Fjob_detail%2F%3Fquery%3D%25E8%2587%25AA%25E5%258A%25A8%25E9%25A9%25BE%25E9%25A9%25B6%26city%3D101020100%26industry%3D%26position%3D; __zp_stoken__=eaf4AHdTnnRrM4tosXCE%2FCPA2IBqs%2BoMIR%2FkL2KsnUmYiwLERJs40PPb8KIurKugecg3l0jmgV1zyN86oQkjtd81dw%3D%3D; Hm_lpvt_194df3105ad7148dcf2b98a91b5e727a=1570159163; __a=64007787.1569672388.1570068443.1570153169.178.6.23.172; __zp_sseed__=4qNlVc1nPWG9Y7G66QfbgtQFW6iSHevalYp+HzrGFH4=; __zp_sname__=9d9e2c78; __zp_sts__=1570159388399'</span></span><br><span class="line">         }</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        html = requests.get(url,headers = header)</span><br><span class="line">        <span class="keyword">if</span> html.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> html.text <span class="comment">#返回列表页的html</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">except</span> RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_job_detial</span><span class="params">(per_page_html)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> per_page_html==<span class="string">''</span> <span class="keyword">or</span> len(per_page_html)==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"未请求到列表页的html！"</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        jobs_title = []</span><br><span class="line">        area = []</span><br><span class="line">        work_exp = []</span><br><span class="line">        edu = []</span><br><span class="line">        company = []</span><br><span class="line">        salary = []</span><br><span class="line">        industry = []</span><br><span class="line">        financing_stage = []</span><br><span class="line">        company_scale = []</span><br><span class="line">        <span class="comment"># 初始化 标准化html</span></span><br><span class="line">        html = etree.HTML(per_page_html) </span><br><span class="line">        <span class="comment"># 工作名</span></span><br><span class="line">        jobs_title = html.xpath(<span class="string">'//div[@class="job-title"]/text()'</span>)</span><br><span class="line">        <span class="comment">#print(jobs_title)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment"># 工作地点</span></span><br><span class="line">        area = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[1]'</span>)</span><br><span class="line">        <span class="comment">#print(area)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#工作经验要求</span></span><br><span class="line">        work_exp = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[2]'</span>)</span><br><span class="line">        <span class="comment">#print(work_exp)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#学历要求</span></span><br><span class="line">        edu = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[3]'</span>)</span><br><span class="line">        <span class="comment">#print(edu)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#公司名</span></span><br><span class="line">        company = html.xpath(<span class="string">'//div[@class="company-text"]//a/text()'</span>)</span><br><span class="line">        <span class="comment">#print(company)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment"># 工资</span></span><br><span class="line">        salary = html.xpath(<span class="string">'//div[@class="info-primary"]//span[@class="red"]/text()'</span>)</span><br><span class="line">        <span class="comment">#print(salary)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#所属行业</span></span><br><span class="line">        industry = html.xpath(<span class="string">'//div[@class="info-company"]//p/text()[1]'</span>)</span><br><span class="line">        <span class="keyword">return</span> jobs_title,area,work_exp,edu,company,salary,industry</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append_job_detial</span><span class="params">(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list,jobs_title,area,work_exp,edu,company,salary,industry)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i,info <span class="keyword">in</span> enumerate(jobs_title):</span><br><span class="line">        jobs_title_list.append(jobs_title[i])</span><br><span class="line">        area_list.append(area[i])</span><br><span class="line">        work_exp_list.append(work_exp[i])</span><br><span class="line">        edu_list.append(edu[i])</span><br><span class="line">        company_list.append(company[i])</span><br><span class="line">        salary_list.append(salary[i])</span><br><span class="line">        industry_list.append(industry[i])</span><br><span class="line">    <span class="keyword">return</span> jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_excel</span><span class="params">(filename,sheet_name,data)</span>:</span></span><br><span class="line">    f = xlwt.Workbook(encoding=<span class="string">'utf-8'</span>)  <span class="comment">#创建一个Workbook 设置编码</span></span><br><span class="line">    <span class="comment"># 第二参数表示是否可以覆盖单元格 其实是 Workbook实例化的一个参数，默认值为False</span></span><br><span class="line">    sheet = f.add_sheet(sheet_name,cell_overwrite_ok=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，</span></span><br><span class="line">    <span class="comment"># 同时列出数据和数据下标，一般用在 for 循环当中。</span></span><br><span class="line">    <span class="keyword">for</span> row,row_data <span class="keyword">in</span> enumerate(data):  <span class="comment">#处理行</span></span><br><span class="line">        <span class="keyword">for</span> column,column_data <span class="keyword">in</span> enumerate(row_data): <span class="comment">#处理列</span></span><br><span class="line">            sheet.write(row,column,str(column_data))</span><br><span class="line">    f.save(filename + <span class="string">".xls"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_detial</span><span class="params">(total_page_count)</span>:</span></span><br><span class="line">    <span class="comment">#循环所有页面，</span></span><br><span class="line">    <span class="comment">#第一步，构造URL获取html</span></span><br><span class="line">    <span class="comment">#第二步，使用bs4解析详情页的超链接，保存到数组中</span></span><br><span class="line">    key_words = <span class="string">"自动驾驶"</span></span><br><span class="line">    key = urllib.parse.quote(key_words) <span class="comment">#将中文进行转码</span></span><br><span class="line">    jobs_title_list = []</span><br><span class="line">    area_list = []</span><br><span class="line">    work_exp_list = []</span><br><span class="line">    edu_list = []</span><br><span class="line">    company_list = []</span><br><span class="line">    salary_list = []</span><br><span class="line">    industry_list = []</span><br><span class="line">    financing_stage_list = []</span><br><span class="line">    company_scale_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,total_page_count+<span class="number">1</span>):   <span class="comment">#查看页面有10页职位列表</span></span><br><span class="line">        print(<span class="string">"正在爬取第 %s 页列表页..."</span> % i)</span><br><span class="line">        url =<span class="string">'https://www.zhipin.com/c100010000/?query='</span>+key+<span class="string">'&amp;page='</span>+str(i)+<span class="string">'&amp;ka=page-'</span>+str(i)</span><br><span class="line">        <span class="comment">#获取每页的列表html</span></span><br><span class="line">        per_page_html = get_job_html(url) </span><br><span class="line">        <span class="comment">#解析提取详情页超的数据</span></span><br><span class="line">        jobs_title,area,work_exp,edu,company,salary,industry\</span><br><span class="line">            =  parse_job_detial(per_page_html) <span class="comment">#,company_scale,financing_stage</span></span><br><span class="line">        <span class="comment"># 将每页30个数据尾加到总的数组</span></span><br><span class="line">        jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list\</span><br><span class="line">            = append_job_detial(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list,\</span><br><span class="line">                jobs_title,area,work_exp,edu,company,salary,industry) <span class="comment">#,financing_stage_list,financing_stage,financing_stage_list,company_scale,,company_scale_list,company_scale_list,</span></span><br><span class="line">        <span class="comment">#随机等待,防止封ip</span></span><br><span class="line">        span=round(random.random()*<span class="number">6</span>,<span class="number">1</span>)</span><br><span class="line">        time.sleep(span)</span><br><span class="line">    print(<span class="string">"爬取列表页完成！"</span>)</span><br><span class="line">    <span class="comment"># 将爬取的数据保存到Excel</span></span><br><span class="line">    jobs_data = list(zip(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list)) <span class="comment">#,company_scale_list</span></span><br><span class="line">    jobs_data.insert(<span class="number">0</span>, (<span class="string">"岗位"</span>,<span class="string">"工作地点"</span>,<span class="string">"工作经验要求"</span>,<span class="string">"学历要求"</span>,<span class="string">"招聘公司"</span>,<span class="string">"工资"</span>,<span class="string">"所属行业"</span>))  <span class="comment">#,"公司规模"</span></span><br><span class="line">    save_to_excel(<span class="string">"jobData"</span>, <span class="string">"AutoDriving"</span>, jobs_data) <span class="comment">#fileName,SheetName,数据</span></span><br><span class="line">    print(<span class="string">"保存数据成功，打开jobData.xls查看"</span>)</span><br><span class="line"></span><br><span class="line">total_page_count = <span class="number">10</span> <span class="comment">#设置爬取列表页页数，10页</span></span><br><span class="line">get_all_detial(total_page_count) <span class="comment">#获取工作的数据保存到Excel</span></span><br></pre></td></tr></tbody></table></figure><img title="获取的数据" data-src="/2019/10/17/BOSS直聘爬虫/图1-4获取的数据.png"><center>图1-4  获取的数据</center><p>  图1-4为获取的目标数据，一共抓取了120个岗位信息。下一步就是对获取的信息进行清洗和统计分析。</p><h2 id="二、数据分析"><a href="#二、数据分析" class="headerlink" title="二、数据分析"></a>二、数据分析</h2><p>  本节主要介绍我们关心哪些信息，并如何对这些的数据进行分析处理和可视化，从而从这些数据中提取出有价值的信息。</p><h3 id="2-1-工作地点全国分布"><a href="#2-1-工作地点全国分布" class="headerlink" title="2.1 工作地点全国分布"></a>2.1 工作地点全国分布</h3><p>  找工作首先关注的点应该是“在哪”工作，找到一个房价便宜工资很高的工作应该是绝大多数求职者的最佳选择。那么“自动驾驶”相关岗位在全国范围内的分布是什么样的情况，本文通过使用优秀的可视化包pyecharts<sup>[1]</sup>实现对招聘岗位全国的分布情况的分析。</p><p><strong>在制作过程中pyecharts的<span class="exturl" data-url="aHR0cHM6Ly9weWVjaGFydHMub3JnLyMvemgtY24v" title="https://pyecharts.org/#/zh-cn/">官方文档<i class="fa fa-external-link"></i></span>起到了很大的作用，以后在开发过程中要重视官方文档的使用。</strong></p><img title="图2-1 自动驾驶职位招聘全国分布" data-src="/2019/10/17/BOSS直聘爬虫/图2-1%20自动驾驶职位招聘全国分布.png"><center>图2-1 自动驾驶职位招聘全国分布</center><img title="图2-2  自动驾驶岗位数量全国TOP10城市" data-src="/2019/10/17/BOSS直聘爬虫/图2-2%20%20自动驾驶岗位数量全国TOP10城市.png"><center>图2-2  自动驾驶岗位数量全国TOP10城市</center><p>代码实现</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Geo</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Bar</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> pyecharts.globals <span class="keyword">import</span> GeoType</span><br><span class="line"><span class="keyword">from</span> pyecharts.render <span class="keyword">import</span> make_snapshot</span><br><span class="line"><span class="keyword">from</span> snapshot_selenium <span class="keyword">import</span> snapshot</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">city_counter</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    全国工作分布热力图</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    datas = pd.read_excel(<span class="string">'jobData.xls'</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">    datas_copy = datas</span><br><span class="line">    datas_copy[<span class="string">'工作地点'</span>] = datas_copy[<span class="string">'工作地点'</span>].apply(<span class="keyword">lambda</span> x :x.split(<span class="string">' '</span>)[<span class="number">0</span>])</span><br><span class="line">    grouped_city = datas_copy.groupby(datas[<span class="string">'工作地点'</span>])</span><br><span class="line">    grouped_city_count = grouped_city[<span class="string">'工作地点'</span>].agg([<span class="string">'count'</span>])    <span class="comment"># 对城市数量进行统计</span></span><br><span class="line">    grouped_city_count.reset_index(inplace = <span class="literal">True</span>)                  <span class="comment"># 若不进行此操作，将会报错 </span></span><br><span class="line">    city_data = [(grouped_city_count[<span class="string">'工作地点'</span>][i], grouped_city_count[<span class="string">'count'</span>][i]) <span class="keyword">for</span> i <span class="keyword">in</span> range(grouped_city_count.shape[<span class="number">0</span>])]</span><br><span class="line">    <span class="comment">#print(city_data)</span></span><br><span class="line">    attr = []</span><br><span class="line">    value = []</span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> city_data:</span><br><span class="line">        attrSub = re.findall(<span class="string">r'[(](.*?)[)]'</span>, str(obj))[<span class="number">0</span>].split(<span class="string">','</span>)[<span class="number">0</span>]</span><br><span class="line">        attr.append(attrSub.split(<span class="string">"'"</span>)[<span class="number">1</span>])</span><br><span class="line">        value.append(int(re.findall(<span class="string">r'[(](.*?)[)]'</span>, str(obj))[<span class="number">0</span>].split(<span class="string">','</span>)[<span class="number">1</span>].strip()))</span><br><span class="line">    <span class="comment">#print(attr)</span></span><br><span class="line">    <span class="comment">#print(value)</span></span><br><span class="line">    <span class="comment"># 全国工作分布热力图</span></span><br><span class="line">    geo = Geo()</span><br><span class="line">    geo = (</span><br><span class="line">        Geo()</span><br><span class="line">        .add_schema(maptype=<span class="string">"china"</span>)</span><br><span class="line">        .add(<span class="string">"岗位数"</span>,[list(z) <span class="keyword">for</span> z <span class="keyword">in</span> zip(attr, value)],symbol_size = <span class="number">20</span>)</span><br><span class="line">        .set_series_opts(label_opts=opts.LabelOpts(is_show=<span class="literal">False</span>)) <span class="comment">#设置图例不可见</span></span><br><span class="line">        .set_global_opts(visualmap_opts=opts.VisualMapOpts(min_=<span class="number">0</span>,max_=<span class="number">40</span>),title_opts=opts.TitleOpts(title=<span class="string">"自动驾驶职位招聘地理位置"</span>))</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">#geo.render('自动驾驶岗位全国热力图.html')</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 全国招聘职位top10地区</span></span><br><span class="line">    city_top10 = sorted(city_data, key = <span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse = <span class="literal">True</span>)[<span class="number">0</span>:<span class="number">10</span>]</span><br><span class="line">    attr = []</span><br><span class="line">    value = []</span><br><span class="line">    <span class="keyword">for</span> obj <span class="keyword">in</span> city_top10:</span><br><span class="line">        attrSub = re.findall(<span class="string">r'[(](.*?)[)]'</span>, str(obj))[<span class="number">0</span>].split(<span class="string">','</span>)[<span class="number">0</span>]</span><br><span class="line">        attr.append(attrSub.split(<span class="string">"'"</span>)[<span class="number">1</span>])</span><br><span class="line">        value.append(int(re.findall(<span class="string">r'[(](.*?)[)]'</span>, str(obj))[<span class="number">0</span>].split(<span class="string">','</span>)[<span class="number">1</span>].strip()))</span><br><span class="line">    bar = (</span><br><span class="line">        Bar()</span><br><span class="line">        .add_xaxis(attr)</span><br><span class="line">        .add_yaxis(<span class="string">"招聘数量"</span>,value)</span><br><span class="line">        .set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"自动驾驶岗位分布柱状图"</span>))</span><br><span class="line">        )</span><br><span class="line">    <span class="comment">#bar.render()</span></span><br><span class="line">    <span class="keyword">return</span> geo,bar</span><br><span class="line"></span><br><span class="line">geo,bar = city_counter()</span><br><span class="line">geo.render(<span class="string">'自动驾驶岗位全国热力图.html'</span>)</span><br><span class="line">bar.render(<span class="string">'自动驾驶岗位分布柱状图.html'</span>)</span><br><span class="line"><span class="comment">#make_snapshot(snapshot, geo.render(), "自动驾驶岗位全国热力图.png") # 使用此语句可直接生成图片</span></span><br><span class="line"><span class="comment">#make_snapshot(snapshot, bar.render(), "自动驾驶岗位分布柱状图.png") # 使用此语句可直接生成图片</span></span><br></pre></td></tr></tbody></table></figure><p>  从图中可以看出“自动驾驶”岗位主要分布在北京、上海、深圳、武汉、苏州、杭州等一线、二线城市，北京、江浙沪（包邮区）和深圳是主要阵地，如果想要从事这个领域的工作，到这些城市去发展有好的环境。</p><h3 id="2-2-薪资水平"><a href="#2-2-薪资水平" class="headerlink" title="2.2 薪资水平"></a>2.2 薪资水平</h3><p>  找工作更重要的是薪资的水平，辛辛苦苦学了很多技能和知识就是为了获得更多的薪资。所以我们来看一下“自动驾驶”岗位的全国范围的薪资水平是怎样的。本文对获取的数据按照城市分类，计算了各个城市的平均薪资水平，如图2-3所示。</p><img title="图2-3  自动驾驶全国平均薪资水平统计" data-src="/2019/10/17/BOSS直聘爬虫/图2-3%20%20自动驾驶全国平均薪资水平统计.png"><center>图2-3  自动驾驶全国平均薪资水平统计</center><p>  从图中可以看出，杭州以35K的平均月薪位居全国第一，全国范围内的平均薪资为18422元/月，佛山最低仅有5000元/月。月薪超过全国平均水平的数量超总体的60%。可以看出，薪资水平最高的城市在杭州、北京、上海、深圳等一线城市，杭州的物价水平和房价低于北上广等城市，落户和生活的成本与北上广相比较低，是一个不错的选择。</p><p>代码实现</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Bar</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> pyecharts.render <span class="keyword">import</span> make_snapshot</span><br><span class="line"><span class="keyword">from</span> snapshot_selenium <span class="keyword">import</span> snapshot</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deal_salary</span><span class="params">(salary_data)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> re.match(<span class="string">'.*K'</span>,salary_data):</span><br><span class="line">        <span class="comment"># 计算平均工资</span></span><br><span class="line">        <span class="keyword">return</span> int(float((float(re.findall(<span class="string">r'(.*?)K'</span>,salary_data)[<span class="number">0</span>].split(<span class="string">'-'</span>)[<span class="number">0</span>])*<span class="number">1000</span>+\</span><br><span class="line">            float(re.findall(<span class="string">r'(.*?)K'</span>,salary_data)[<span class="number">0</span>].split(<span class="string">'-'</span>)[<span class="number">1</span>])*<span class="number">1000</span>)/<span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">city_salary</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">每个城市的平均工资条形统计图</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">    datas = pd.read_excel(<span class="string">'jobData.xls'</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">    datas_copy = datas</span><br><span class="line">    datas_copy[<span class="string">'工作地点'</span>] = datas_copy[<span class="string">'工作地点'</span>].apply(<span class="keyword">lambda</span> x :x.split(<span class="string">' '</span>)[<span class="number">0</span>])</span><br><span class="line">    datas_copy = datas_copy[~datas_copy[<span class="string">'工资'</span>].str.contains(<span class="string">'天'</span>)] <span class="comment"># 除去实习的数据</span></span><br><span class="line">    datas_copy = datas_copy[~datas_copy[<span class="string">'工资'</span>].isna()] <span class="comment"># 除去工资为空的值</span></span><br><span class="line">    datas_copy[<span class="string">'工资'</span>] = datas_copy[<span class="string">'工资'</span>].apply(<span class="keyword">lambda</span> x :deal_salary(x))</span><br><span class="line">    grouped_city_salary = datas_copy[<span class="string">'工资'</span>].groupby(datas_copy[<span class="string">'工作地点'</span>])</span><br><span class="line">    salary_month = grouped_city_salary.agg([<span class="string">'mean'</span>]) <span class="comment">#计算各个城市的平均工资</span></span><br><span class="line">    salary_month.reset_index(inplace = <span class="literal">True</span>)</span><br><span class="line">    attr = []</span><br><span class="line">    value = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(salary_month.shape[<span class="number">0</span>]):</span><br><span class="line">        attr.append(salary_month[<span class="string">'工作地点'</span>][i])</span><br><span class="line">        value.append(str(salary_month[<span class="string">'mean'</span>][i])) <span class="comment">#将 int 数字转化为 string才能显示图片</span></span><br><span class="line">    bar = (</span><br><span class="line">        Bar()</span><br><span class="line">        .add_xaxis(attr)</span><br><span class="line">        .add_yaxis(<span class="string">"工资(元)"</span>,value)</span><br><span class="line">        .set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"城市平均工资统计图"</span>))</span><br><span class="line">        .set_series_opts(</span><br><span class="line">            label_opts=opts.LabelOpts(is_show=<span class="literal">False</span>),</span><br><span class="line">            markline_opts=opts.MarkLineOpts(</span><br><span class="line">                data=[</span><br><span class="line">                    opts.MarkLineItem(type_=<span class="string">"average"</span>, name=<span class="string">"平均值"</span>)</span><br><span class="line">                ]</span><br><span class="line">            ),</span><br><span class="line">            markpoint_opts=opts.MarkPointOpts(</span><br><span class="line">                data=[</span><br><span class="line">                    opts.MarkPointItem(type_=<span class="string">"max"</span>, name=<span class="string">"最大值"</span>),</span><br><span class="line">                    opts.MarkPointItem(type_=<span class="string">"min"</span>, name=<span class="string">"最小值"</span>),</span><br><span class="line">                ]</span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> bar</span><br><span class="line"></span><br><span class="line">city_mean_salary = city_salary()</span><br><span class="line">city_mean_salary.render()</span><br><span class="line"><span class="comment">#make_snapshot(snapshot, city_mean_salary.render(), "城市平均工资统计图.png") # 使用此语句可直接生成图片</span></span><br></pre></td></tr></tbody></table></figure><h3 id="2-3-学历、工作经验要求"><a href="#2-3-学历、工作经验要求" class="headerlink" title="2.3 学历、工作经验要求"></a>2.3 学历、工作经验要求</h3><p>  你可能会问这些岗位这么好，会对学历有很高的要求吗？（学历在不同行业都是越高越好吗？）对工作经验又有什么样的要求呢？那么我们就通过数据来看一下结果吧，通过对所获取信息中的学历要求、工作经验进行统计，绘制“自动驾驶”职位学历要求饼图、工作经验要求饼图如图2-4和图2-5所示。</p><img title="图2-4  “自动驾驶”职位学历要求" data-src="/2019/10/17/BOSS直聘爬虫/图2-4%20%20“自动驾驶”职位学历要求.png"><center>图2-4  “自动驾驶”职位学历要求</center><img title="图2-5  “自动驾驶”职位工作经验要求" data-src="/2019/10/17/BOSS直聘爬虫/图2-5%20%20“自动驾驶”职位工作经验要求.png"><center>图2-5  “自动驾驶”职位工作经验要求</center><p>  通过统计结果可以看出，在获取的岗位招聘信息中，自动驾驶相关岗位对学历的要求不是很高，本科学历要求占75%以上，硕士学历要求占15%左右。结合经验要求来看，大部分的公司要求是经验不限和1-5年，这几个时间范围占了主要部分，所以结合这两个信息，认为“自动驾驶”岗位更加看重工作经验，只要有本科的学历，经验丰富能力强就可以找到不错的工作。</p><p>代码实现</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Page, Pie</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> pyecharts.render <span class="keyword">import</span> make_snapshot</span><br><span class="line"><span class="keyword">from</span> snapshot_selenium <span class="keyword">import</span> snapshot</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">edu_require</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">学历要求饼图</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">    datas = pd.read_excel(<span class="string">'jobData.xls'</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">    datas_copy = datas</span><br><span class="line">    datas_copy = datas_copy[~datas_copy[<span class="string">'学历要求'</span>].str.contains(<span class="string">'个月'</span>)]   <span class="comment"># 去掉实习工作</span></span><br><span class="line">    grouped_eductaion = datas_copy.groupby(datas_copy[<span class="string">'学历要求'</span>]) <span class="comment"># 按学历分组</span></span><br><span class="line">    grouped_eductaion_count = grouped_eductaion[<span class="string">'学历要求'</span>].agg([<span class="string">'count'</span>]) <span class="comment"># 统计不同分组的数量</span></span><br><span class="line">    grouped_eductaion_count.reset_index(inplace = <span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># edu_data = [(grouped_eductaion_count['学历要求'][i], grouped_eductaion_count['count'][i]) for i in range(grouped_eductaion_count.shape[0])]</span></span><br><span class="line">    attr = []</span><br><span class="line">    value = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(grouped_eductaion_count.shape[<span class="number">0</span>]):</span><br><span class="line">        attr.append(grouped_eductaion_count[<span class="string">'学历要求'</span>][i])</span><br><span class="line">        value.append(str(grouped_eductaion_count[<span class="string">'count'</span>][i])) <span class="comment">#将 int 数字转化为 string才能显示图片</span></span><br><span class="line">    pie = (</span><br><span class="line">        Pie()</span><br><span class="line">        .add(</span><br><span class="line">            <span class="string">""</span>,</span><br><span class="line">            [list(z) <span class="keyword">for</span> z <span class="keyword">in</span> zip(attr, value)],</span><br><span class="line">            radius=[<span class="string">"40%"</span>, <span class="string">"75%"</span>]</span><br><span class="line">        )</span><br><span class="line">        .set_global_opts(</span><br><span class="line">            title_opts=opts.TitleOpts(title=<span class="string">"学历要求"</span>),</span><br><span class="line">            legend_opts=opts.LegendOpts(</span><br><span class="line">                orient=<span class="string">"vertical"</span>, pos_top=<span class="string">"15%"</span>, pos_left=<span class="string">"2%"</span></span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        .set_series_opts(label_opts=opts.LabelOpts(formatter=<span class="string">"{b}: {c}"</span>))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> pie</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">exp_require</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">工作经验要求饼图</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">    datas = pd.read_excel(<span class="string">'jobData.xls'</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">    datas_copy = datas</span><br><span class="line">    datas_copy = datas_copy[~datas_copy[<span class="string">'工作经验要求'</span>].str.contains(<span class="string">'天/周'</span>)]   <span class="comment"># 去掉实习工作</span></span><br><span class="line">    grouped_exp = datas_copy.groupby(datas_copy[<span class="string">'工作经验要求'</span>]) <span class="comment"># 按工作经验分组</span></span><br><span class="line">    grouped_exp_count = grouped_exp[<span class="string">'工作经验要求'</span>].agg([<span class="string">'count'</span>]) <span class="comment"># 统计不同分组的数量</span></span><br><span class="line">    grouped_exp_count.reset_index(inplace = <span class="literal">True</span>)</span><br><span class="line">    attr = []</span><br><span class="line">    value = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(grouped_exp_count.shape[<span class="number">0</span>]):</span><br><span class="line">        attr.append(grouped_exp_count[<span class="string">'工作经验要求'</span>][i])</span><br><span class="line">        value.append(str(grouped_exp_count[<span class="string">'count'</span>][i])) <span class="comment">#将 int 数字转化为 string才能显示图片</span></span><br><span class="line">    pie = (</span><br><span class="line">        Pie()</span><br><span class="line">        .add(</span><br><span class="line">            <span class="string">""</span>,</span><br><span class="line">            [list(z) <span class="keyword">for</span> z <span class="keyword">in</span> zip(attr, value)],</span><br><span class="line">            radius=[<span class="string">"40%"</span>, <span class="string">"75%"</span>]</span><br><span class="line">        )</span><br><span class="line">        .set_global_opts(</span><br><span class="line">            title_opts=opts.TitleOpts(title=<span class="string">"工作经验要求"</span>),</span><br><span class="line">            legend_opts=opts.LegendOpts(</span><br><span class="line">                orient=<span class="string">"vertical"</span>, pos_top=<span class="string">"15%"</span>, pos_left=<span class="string">"2%"</span></span><br><span class="line">            )</span><br><span class="line">        )</span><br><span class="line">        .set_series_opts(label_opts=opts.LabelOpts(formatter=<span class="string">"{b}: {c}"</span>))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> pie</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">edu_pie = edu_require()</span><br><span class="line">edu_pie.render(<span class="string">"学历要求饼图.html"</span>)</span><br><span class="line">exp_pie = exp_require()</span><br><span class="line">exp_pie.render(<span class="string">"工作经验要求饼图.html"</span>)</span><br><span class="line"><span class="comment">#make_snapshot(snapshot, edu_pie.render(), "学历要求饼图.png") # 使用此语句可直接生成图片</span></span><br><span class="line"><span class="comment">#make_snapshot(snapshot, exp_pie.render(), "工作经验要求饼图.png") # 使用此语句可直接生成图片</span></span><br></pre></td></tr></tbody></table></figure><h3 id="2-4-工作种类、主要企业、行业分布"><a href="#2-4-工作种类、主要企业、行业分布" class="headerlink" title="2.4 工作种类、主要企业、行业分布"></a>2.4 工作种类、主要企业、行业分布</h3><p>  分析完学历与工作经验，我们来分析一下这些工作主要包括哪些种类，也就是说“自动驾驶”的招聘岗位主要包括哪些，可以为求职者提供学习的方向。为了更好地展示数据分析的成果，我们使用了优秀的开源包<span class="exturl" data-url="aHR0cHM6Ly9weXBpLm9yZy9wcm9qZWN0L2ppZWJhLw==" title="https://pypi.org/project/jieba/">jieba<i class="fa fa-external-link"></i></span>以及强大、方便的可视化工具<span class="exturl" data-url="aHR0cHM6Ly9weXBpLm9yZy9wcm9qZWN0L3B5ZWNoYXJ0cy8=" title="https://pypi.org/project/pyecharts/">pyecharts<i class="fa fa-external-link"></i></span>展示，根据“工作名”这一项数据项先进行分词，然后绘制了词云如图2-6所示。</p><img title="图2-6  “自动驾驶”主要岗位种类分析" data-src="/2019/10/17/BOSS直聘爬虫/图2-6%20%20“自动驾驶”主要岗位种类分析.png"><center>图2-6  “自动驾驶”主要岗位种类分析</center><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Page, WordCloud</span><br><span class="line"><span class="keyword">from</span> pyecharts.globals <span class="keyword">import</span> SymbolType</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">job_title</span><span class="params">()</span>:</span></span><br><span class="line">    datas = pd.read_excel(<span class="string">'jobData.xls'</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">    datas_copy = datas</span><br><span class="line">    text = <span class="string">''</span>.join(datas_copy[<span class="string">'岗位'</span>])</span><br><span class="line">    requirements = [word <span class="keyword">for</span> word <span class="keyword">in</span> jieba.cut(text, cut_all=<span class="literal">True</span>)] <span class="comment"># 全模式分词</span></span><br><span class="line">    requirements_top = Counter(requirements)  <span class="comment"># Counter()函数对str进行统计</span></span><br><span class="line">    requirements_top50 = requirements_top.most_common(<span class="number">50</span>)    <span class="comment"># 统计最多的50个 ，most_common返回(string , count)的数据形式</span></span><br><span class="line">    c = (</span><br><span class="line">        WordCloud()</span><br><span class="line">        .add(<span class="string">""</span>, requirements_top50, word_size_range=[<span class="number">20</span>, <span class="number">100</span>], shape=SymbolType.DIAMOND)</span><br><span class="line">        .set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"主要岗位名称"</span>))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line">job_title = job_title()</span><br><span class="line">job_title.render(<span class="string">"主要岗位名称.html"</span>)</span><br></pre></td></tr></tbody></table></figure><p>  从图中可以看出，<code>算法</code>、<code>规划</code>、<code>感知</code>、<code>控制</code>、<code>嵌入式</code>等关键词频率较高，所以想要从事这一领域的工作，可以多多关注和学习这些领域的知识。为以后的求职做好准备，打下基础。<br>  那么哪些公司是招聘的大户呢？即招聘岗位数量较多的企业有哪些？我们使用同样的方法绘制了基于企业招聘数量的词云如图2-7所示。</p><img title="图2-7  “自动驾驶”主要招聘企业" data-src="/2019/10/17/BOSS直聘爬虫/图2-7%20%20“自动驾驶”主要招聘企业.png"><center>图2-7  “自动驾驶”主要招聘企业</center><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Page, WordCloud</span><br><span class="line"><span class="keyword">from</span> pyecharts.globals <span class="keyword">import</span> SymbolType</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">company_count</span><span class="params">()</span>:</span></span><br><span class="line">    datas = pd.read_excel(<span class="string">'jobData.xls'</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">    datas_copy = datas</span><br><span class="line">    grouped_company = datas_copy.groupby(datas_copy[<span class="string">'招聘公司'</span>]) <span class="comment"># 按招聘公司分组</span></span><br><span class="line">    grouped_company_count = grouped_company[<span class="string">'招聘公司'</span>].agg([<span class="string">'count'</span>]) <span class="comment"># 统计不同分组的数量</span></span><br><span class="line">    grouped_company_count.reset_index(inplace = <span class="literal">True</span>)</span><br><span class="line">    company_data = [(grouped_company_count[<span class="string">'招聘公司'</span>][i],str(grouped_company_count[<span class="string">'count'</span>][i])) \</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(grouped_company_count.shape[<span class="number">0</span>])]</span><br><span class="line">    <span class="comment"># 是否要将数字转化为str</span></span><br><span class="line"></span><br><span class="line">    c = (</span><br><span class="line">        WordCloud()</span><br><span class="line">        .add(<span class="string">""</span>, company_data, word_size_range=[<span class="number">20</span>, <span class="number">100</span>], shape=SymbolType.DIAMOND)</span><br><span class="line">        .set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"主要的招聘公司"</span>))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line">company_count = company_count()</span><br><span class="line">company_count.render(<span class="string">"主要的招聘公司.html"</span>)</span><br><span class="line"><span class="comment">#make_snapshot(snapshot, company_count.render(), "主要的招聘公司.png") # 使用此语句可直接生成图片</span></span><br></pre></td></tr></tbody></table></figure><p>  可以看出，招聘数量排在前几位的分别有禾多科技、<span class="exturl" data-url="aHR0cHM6Ly93d3cuZGVlcGJsdWVhaS5jb20=" title="https://www.deepblueai.com">深兰科技<i class="fa fa-external-link"></i></span>、<span class="exturl" data-url="aHR0cHM6Ly93d3cuY3Rpcm9ib3QuY29t" title="https://www.ctirobot.com">坎德拉<i class="fa fa-external-link"></i></span>、<span class="exturl" data-url="aHR0cDovL3d3dy41MWhpdGVjaC5jb20=" title="http://www.51hitech.com">51VR<i class="fa fa-external-link"></i></span>、<span class="exturl" data-url="aHR0cDovL3d3dy5rb3RlaS5jb20uY24=" title="http://www.kotei.com.cn">武汉光庭科技<i class="fa fa-external-link"></i></span>、<span class="exturl" data-url="aHR0cDovL3d3dy55aWhhbmcuYWk=" title="http://www.yihang.ai">易航<i class="fa fa-external-link"></i></span>等公司，互联网大厂腾讯、华为，传统车厂吉利集团紧随其后，还有很多年轻的企业也有上榜。</p><p>  这些岗位所属的行业又有哪些呢？我们使用同样的方法统计如图2-8所示。</p><img title="图2-8  自动驾驶招聘行业分布" data-src="/2019/10/17/BOSS直聘爬虫/图2-8%20%20自动驾驶招聘行业分布.png"><center>图2-8  自动驾驶招聘行业分布</center><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> pyecharts <span class="keyword">import</span> options <span class="keyword">as</span> opts</span><br><span class="line"><span class="keyword">from</span> pyecharts.charts <span class="keyword">import</span> Page, WordCloud</span><br><span class="line"><span class="keyword">from</span> pyecharts.globals <span class="keyword">import</span> SymbolType</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">industry</span><span class="params">()</span>:</span></span><br><span class="line">    datas = pd.read_excel(<span class="string">'jobData.xls'</span>, encoding = <span class="string">'utf-8'</span>)</span><br><span class="line">    datas_copy = datas</span><br><span class="line">    grouped_industry = datas_copy.groupby(datas_copy[<span class="string">'所属行业'</span>]) <span class="comment"># 按所属行业分组</span></span><br><span class="line">    grouped_industry_count = grouped_industry[<span class="string">'所属行业'</span>].agg([<span class="string">'count'</span>]) <span class="comment"># 统计不同分组的数量</span></span><br><span class="line">    grouped_industry_count.reset_index(inplace = <span class="literal">True</span>)</span><br><span class="line">    industry_data = [(grouped_industry_count[<span class="string">'所属行业'</span>][i],str(grouped_industry_count[<span class="string">'count'</span>][i])) \</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(grouped_industry_count.shape[<span class="number">0</span>])]</span><br><span class="line">    c = (</span><br><span class="line">        WordCloud()</span><br><span class="line">        .add(<span class="string">""</span>, industry_data, word_size_range=[<span class="number">20</span>, <span class="number">100</span>], shape=SymbolType.DIAMOND)</span><br><span class="line">        .set_global_opts(title_opts=opts.TitleOpts(title=<span class="string">"自动驾驶岗位行业分布"</span>))</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> c</span><br><span class="line"></span><br><span class="line">industry_distribution = industry()</span><br><span class="line">industry_distribution.render(<span class="string">"自动驾驶岗位行业分布.html"</span>)</span><br><span class="line"><span class="comment">#make_snapshot(snapshot, industry_distribution.render(), "自动驾驶岗位行业分布.png") # 使用此语句可直接生成图片</span></span><br></pre></td></tr></tbody></table></figure><p>  从图中可以看出现在“自动驾驶”的企业所示行业多为“计算机互联网”、“智能硬件”以及“汽车生产”行业，这三类行业是招聘的主力军。</p><h2 id="三、总结与讨论"><a href="#三、总结与讨论" class="headerlink" title="三、总结与讨论"></a>三、总结与讨论</h2><h3 id="3-1-总结"><a href="#3-1-总结" class="headerlink" title="3.1 总结"></a>3.1 总结</h3><p>从两个方面进行总结，</p><ul><li><p>首先是内容上：从数据的分析中对于<strong>自动驾驶</strong>岗位的招聘需求有了进一步的认识，自动驾驶相关岗位主要的工作内容有<strong>算法、规划、感知、控制、嵌入式</strong>，北京、江浙沪（包邮区）和深圳是主要的工作地点，全国范围内的平均薪资为18422元/月，自动驾驶岗位更加看重工作经验、学历多数要求为本科，所在行业一般为<strong>计算机互联网、智能硬件以及汽车生产</strong>，招聘需求较多的企业有禾多科技、深兰科技、坎德拉、51VR、武汉光庭科技、易航等公司。</p></li><li><p>其次是技术上总结：<br>在数据获取中学会使用开发者工具发现网页规律；在数据解析中学会使用<code>xpath</code>、<code>beautifulSoup</code>；数据分析中学会使用<code>pyecharts</code>绘制多种有趣的可视化图片，学会使用<code>jieba</code>包统计词频。</p></li></ul><h3 id="3-2-遇到的问题"><a href="#3-2-遇到的问题" class="headerlink" title="3.2 遇到的问题"></a>3.2 遇到的问题</h3><p>  本文一开始想要获取更详细的<code>工作职责</code>和<code>工作技能要求</code>的数据，在爬取详情页的过程中发现BOSS直聘在请求详情页时每次的请求都会产生不同的<code>cookie</code>，否则无法获取想要的html，会跳转到其他页面，经过google查询已经有前辈发现了这个问题，但是还未找到解决的反反爬方法（魔高一尺道高一丈）。所以改为爬取较为容易获取的详情页面。</p><h3 id="3-3-不足之处"><a href="#3-3-不足之处" class="headerlink" title="3.3 不足之处"></a>3.3 不足之处</h3><p>  本文仅仅分析了BOSS直聘一家的数据，数据来源与实际情况有一定的差别，但是能体现一定的代表性，未来可以进行多家招聘网站（如<strong>智联招聘、51job招聘，前程无忧</strong>等）的数据爬取，提高数据的可信度。</p><h3 id="3-4-未来工作"><a href="#3-4-未来工作" class="headerlink" title="3.4 未来工作"></a>3.4 未来工作</h3><p>  目前已经完成数据的<code>获取、分析、统计、可视化</code>，未来还可以对数据之间的<code>相关性</code>进行<code>建模分析</code>，得出有意思、有价值的结论。（例如，哪些数据对薪资有影响？）</p><h3 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h3><p>  <em>本文的主要方法与技术代码参考了网络上的博客，在此一并致谢！</em></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]    LI D, MEI H, YI S, et al. ECharts: A declarative framework for rapid construction of web-based visualization ☆ [J]. Visual Informatics, 2018, S2468502X18300068-.</p><p>[2] <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjkzNzU4L2FydGljbGUvZGV0YWlscy84ODU3MzM2MA==" title="https://blog.csdn.net/qq_42293758/article/details/88573360">Python爬取岗位数据并分析<i class="fa fa-external-link"></i></span></p><p>[3] <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzMDY5NC9hcnRpY2xlL2RldGFpbHMvOTY2NTAyODE=" title="https://blog.csdn.net/weixin_43930694/article/details/96650281">Python3 + xpath + excel 实现对boss直聘网的爬取<i class="fa fa-external-link"></i></span></p><p>[4] <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI3NjY4MzEzL2FydGljbGUvZGV0YWlscy84MjkyNDYyMg==" title="https://blog.csdn.net/qq_27668313/article/details/82924622">BOSS直聘网站数据分析岗位信息爬取<i class="fa fa-external-link"></i></span></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;  这是我个人博客的第一篇文章，是全新的开始。希望未来在这里记录更多有趣的探索。&lt;/p&gt;
&lt;img title=&quot;自动驾驶岗位名称&quot; data-src=&quot;/2019/10/17/BOSS直聘爬虫/岗位名称.jpg&quot;&gt;
&lt;p&gt;  自动驾驶随着人工智能技术的成熟，人才需求在不断增加，为了对我国自动驾驶人才需求进行了解，本文选择&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly93d3cuemhpcGluLmNvbQ==&quot; title=&quot;https://www.zhipin.com&quot;&gt;BOSS直聘&lt;i class=&quot;fa fa-external-link&quot;&gt;&lt;/i&gt;&lt;/span&gt;招聘网站获取自动驾驶相关职位信息，分析数据，根据分析结果确定人才需求、为以后的学习制定计划。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="2019秋《交通数据分析》" scheme="http://www.caoxu.club/categories/2019%E7%A7%8B%E3%80%8A%E4%BA%A4%E9%80%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%8B/"/>
    
      <category term="数据爬取" scheme="http://www.caoxu.club/categories/2019%E7%A7%8B%E3%80%8A%E4%BA%A4%E9%80%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%8B/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/"/>
    
    
      <category term="python" scheme="http://www.caoxu.club/tags/python/"/>
    
      <category term="爬虫" scheme="http://www.caoxu.club/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="工作信息" scheme="http://www.caoxu.club/tags/%E5%B7%A5%E4%BD%9C%E4%BF%A1%E6%81%AF/"/>
    
      <category term="可视化" scheme="http://www.caoxu.club/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    
      <category term="pyecharts" scheme="http://www.caoxu.club/tags/pyecharts/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://www.caoxu.club/2019/10/12/hello-world/"/>
    <id>http://www.caoxu.club/2019/10/12/hello-world/</id>
    <published>2019-10-12T13:25:37.410Z</published>
    <updated>2019-10-14T16:39:38.421Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvLw==" title="https://hexo.io/">Hexo<i class="fa fa-external-link"></i></span>! This is your very first post. Check <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL2RvY3Mv" title="https://hexo.io/docs/">documentation<i class="fa fa-external-link"></i></span> for more info. If you get any problems when using Hexo, you can find the answer in <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL2RvY3MvdHJvdWJsZXNob290aW5nLmh0bWw=" title="https://hexo.io/docs/troubleshooting.html">troubleshooting<i class="fa fa-external-link"></i></span> or you can ask me on <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2hleG9qcy9oZXhvL2lzc3Vlcw==" title="https://github.com/hexojs/hexo/issues">GitHub<i class="fa fa-external-link"></i></span>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></tbody></table></figure><p>More info: <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvd3JpdGluZy5odG1s" title="https://hexo.io/docs/writing.html">Writing<i class="fa fa-external-link"></i></span></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></tbody></table></figure><p>More info: <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvc2VydmVyLmh0bWw=" title="https://hexo.io/docs/server.html">Server<i class="fa fa-external-link"></i></span></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></tbody></table></figure><p>More info: <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL2RvY3MvZ2VuZXJhdGluZy5odG1s" title="https://hexo.io/docs/generating.html">Generating<i class="fa fa-external-link"></i></span></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></tbody></table></figure><p>More info: <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL2RvY3MvZGVwbG95bWVudC5odG1s" title="https://hexo.io/docs/deployment.html">Deployment<i class="fa fa-external-link"></i></span></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly9oZXhvLmlvLw==&quot; title=&quot;https://hexo.io/&quot;&gt;Hexo&lt;i class=&quot;fa fa-external-link&quot;&gt;&lt;/i&gt;&lt;/spa
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
