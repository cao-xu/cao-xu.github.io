<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>CaoXu&#39;s Blog</title>
  
  <subtitle>想法、创意与实践</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.caoxu.club/"/>
  <updated>2019-10-17T13:41:40.890Z</updated>
  <id>http://www.caoxu.club/</id>
  
  <author>
    <name>CaoXu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>BOSS直聘“自动驾驶”岗位信息爬取与分析</title>
    <link href="http://www.caoxu.club/2019/10/17/BOSS%E7%9B%B4%E8%81%98%E7%88%AC%E8%99%AB/"/>
    <id>http://www.caoxu.club/2019/10/17/BOSS直聘爬虫/</id>
    <published>2019-10-17T07:40:49.000Z</published>
    <updated>2019-10-17T13:41:40.890Z</updated>
    
    <content type="html"><![CDATA[<p>  这是我个人博客的第一篇文章，是全新的开始。希望未来在这里记录更多有趣的探索。</p><img title="自动驾驶岗位名称" data-src="/2019/10/17/BOSS直聘爬虫/岗位名称.jpg"><p>  自动驾驶随着人工智能技术的成熟，人才需求在不断增加，为了对我国自动驾驶人才需求进行了解，本文选择<span class="exturl" data-url="aHR0cHM6Ly93d3cuemhpcGluLmNvbQ==" title="https://www.zhipin.com">BOSS直聘<i class="fa fa-external-link"></i></span>招聘网站获取自动驾驶相关职位信息，分析数据，根据分析结果确定人才需求、为以后的学习制定计划。<br><a id="more"></a></p><p>本文开发环境：<span class="exturl" data-url="aHR0cHM6Ly93d3cucHl0aG9uLm9yZw==" title="https://www.python.org">python3.7<i class="fa fa-external-link"></i></span> 、<span class="exturl" data-url="aHR0cHM6Ly93d3cuYW5hY29uZGEuY29t" title="https://www.anaconda.com">anconda3<i class="fa fa-external-link"></i></span></p><h2 id="一、数据爬取"><a href="#一、数据爬取" class="headerlink" title="一、数据爬取"></a>一、数据爬取</h2><h3 id="1-1-分析目标页，构造URL"><a href="#1-1-分析目标页，构造URL" class="headerlink" title="1.1 分析目标页，构造URL"></a>1.1 分析目标页，构造URL</h3><p>  首先，进入网站输入关键字“自动驾驶”查询得到职位的列表页面，对目标页面的URL分析<code>https://www.zhipin.com/c101010100/?query=自动驾驶&amp;page=1&amp;ka=page-1</code>，发现关键的字段有：<code>query</code>、<code>page</code>分别代表了要查询的<strong>关键字</strong>和<strong>页面</strong>，<code>c101010100</code>代表了城市的编号，当选择了<strong>全国</strong>时编号为<code>c101010100</code>，所以通过控制这三个参数，实现对全国所有职位列表页的信息的爬取。</p><img title="目标页面" data-src="/2019/10/17/BOSS直聘爬虫/图1-1目标页面.png"><center>图1-1  目标页面</center><p>  其次，构建headers cookie，通过尝试发现爬取Boss直聘必须添加cookie，构建的请求头如下。</p><p><code>header = {         'User-Agent':            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36',         'Cookie':            '_uab_collina=156967238793885639512262；bannerClose_wanmeishijie=true; lastCity=101010100; _bl_uid=q5k7F1m8aOIjLLybtrIhbILink0X; __c=1570153169; __g=-;Hm_lvt_194df3105ad7148dcf2b98a91b5e727a=1569912508,1569985933,1570068443,1570153169;__l=l=%2Fwww.zhipin.com%2F&amp;r=&amp;friend_source=0&amp;friend_source=0;toUrl=https%3A%2F%2Fwww.zhipin.com%2Fjob_detail%2F%3Fquery%3D%25E8%2587%25AA%25E5%258A%25A8%25E9%25A9%25BE%25E9%25A9%25B6%26city%3D101020100%26industry%3D%26position%3D;__zp_stoken__=eaf4AHdTnnRrM4tosXCE%2FCPA2IBqs%2BoMIR%2FkL2KsnUmYiwLERJs40PPb8KIurKugecg3l0jmgV1zyN86oQkjtd81dw%3D%3D;Hm_lpvt_194df3105ad7148dcf2b98a91b5e727a=1570159163;__a=64007787.1569672388.1570068443.1570153169.178.6.23.172;__zp_sseed__=4qNlVc1nPWG9Y7G66QfbgtQFW6iSHevalYp+HzrGFH4=; __zp_sname__=9d9e2c78;__zp_sts__=1570159388399'        }</code></p><h3 id="1-2-爬取、解析数据并保存"><a href="#1-2-爬取、解析数据并保存" class="headerlink" title="1.2 爬取、解析数据并保存"></a>1.2 爬取、解析数据并保存</h3><h4 id="1-2-1-确定要爬取的信息"><a href="#1-2-1-确定要爬取的信息" class="headerlink" title="1.2.1 确定要爬取的信息"></a>1.2.1 确定要爬取的信息</h4><p>  F12打开开发者工具，审查网页元素，需要获取的信息包括“工作名、薪资、工作地点、工作经验、学历要求、企业名、企业所属行业”。</p><img title="目标页面" data-src="/2019/10/17/BOSS直聘爬虫/图1-2分析目标页面.png"><center>图1-2  分析目标页面</center><h4 id="1-2-2-发送请求、解析数据、保存数据"><a href="#1-2-2-发送请求、解析数据、保存数据" class="headerlink" title="1.2.2 发送请求、解析数据、保存数据"></a>1.2.2 发送请求、解析数据、保存数据</h4><p>  对目标页面发送请求后，解析返回的html并提取所需要的信息，这里主要用到的包有：<code>urllib</code>、<code>requests</code>、<code>BeautifulSoup</code>、<code>lxml</code>。函数的主要步骤为：</p><ul><li>第一步，请求目标页面html</li><li>第二步，使用<code>lxml</code>和<code>bs4</code>解析目标信息</li><li>第三步，随机等待几秒，防止ip被封</li></ul><p>循环完成对所有页面岗位信息的提取，当完成数据的解析后，将数据保存到Excel表格中。下面的代码实现上述发送请求、解析数据、保存数据步骤。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_detial</span><span class="params">(total_page_count)</span>:</span></span><br><span class="line">    <span class="comment">#循环所有页面，</span></span><br><span class="line">    <span class="comment">#第一步，构造URL获取html</span></span><br><span class="line">    <span class="comment">#第二步，使用bs4解析详情页的超链接，保存到数组中</span></span><br><span class="line">    key_words = <span class="string">"自动驾驶"</span></span><br><span class="line">    key = urllib.parse.quote(key_words) <span class="comment">#将中文进行转码</span></span><br><span class="line">    jobs_title_list = []</span><br><span class="line">    area_list = []</span><br><span class="line">    work_exp_list = []</span><br><span class="line">    edu_list = []</span><br><span class="line">    company_list = []</span><br><span class="line">    salary_list = []</span><br><span class="line">    industry_list = []</span><br><span class="line">    financing_stage_list = []</span><br><span class="line">    company_scale_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,total_page_count+<span class="number">1</span>):   <span class="comment">#查看页面有10页职位列表</span></span><br><span class="line">        print(<span class="string">"正在爬取第 %s 页列表页..."</span> % i)</span><br><span class="line">        url =<span class="string">'https://www.zhipin.com/c100010000/?query='</span>+key+<span class="string">'&amp;page='</span>+str(i)+<span class="string">'&amp;ka=page-'</span>+str(i)</span><br><span class="line">        <span class="comment">#获取每页的列表html</span></span><br><span class="line">        per_page_html = get_job_html(url) </span><br><span class="line">        <span class="comment">#解析提取详情页超的数据</span></span><br><span class="line">        jobs_title,area,work_exp,edu,company,salary,industry\</span><br><span class="line">            =  parse_job_detial(per_page_html) <span class="comment">#,company_scale,financing_stage</span></span><br><span class="line">        <span class="comment"># 将每页30个数据尾加到总的数组</span></span><br><span class="line">        jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list\</span><br><span class="line">            = append_job_detial(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list,\</span><br><span class="line">                jobs_title,area,work_exp,edu,company,salary,industry) </span><br><span class="line">        <span class="comment">#随机等待,防止封ip</span></span><br><span class="line">        span=round(random.random()*<span class="number">6</span>,<span class="number">1</span>)</span><br><span class="line">        time.sleep(span)</span><br><span class="line">    print(<span class="string">"爬取列表页完成！"</span>)</span><br><span class="line">    <span class="comment"># 将爬取的数据保存到Excel</span></span><br><span class="line">    jobs_data = list(zip(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list)) </span><br><span class="line">    jobs_data.insert(<span class="number">0</span>, (<span class="string">"岗位"</span>,<span class="string">"工作地点"</span>,<span class="string">"工作经验要求"</span>,<span class="string">"学历要求"</span>,<span class="string">"招聘公司"</span>,<span class="string">"工资"</span>,<span class="string">"所属行业"</span>))</span><br><span class="line">    save_to_excel(<span class="string">"jobData"</span>, <span class="string">"AutoDriving"</span>, jobs_data) <span class="comment">#fileName,SheetName,数据</span></span><br><span class="line">    print(<span class="string">"保存数据成功，打开jobData.xls查看"</span>)</span><br></pre></td></tr></tbody></table></figure><p>  <code>get_job_html(url)</code>函数实现请求目标<code>url</code>，代码实现如下。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_job_html</span><span class="params">(url)</span>:</span></span><br><span class="line">    header = {</span><br><span class="line">         <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'</span>,</span><br><span class="line">         <span class="string">'Cookie'</span>:<span class="string">'_uab_collina=156967238793885639512262; bannerClose_wanmeishijie=true; lastCity=101010100; _bl_uid=q5k7F1m8aOIjLLybtrIhbILink0X; __c=1570153169; __g=-; Hm_lvt_194df3105ad7148dcf2b98a91b5e727a=1569912508,1569985933,1570068443,1570153169; __l=l=%2Fwww.zhipin.com%2F&amp;r=&amp;friend_source=0&amp;friend_source=0; toUrl=https%3A%2F%2Fwww.zhipin.com%2Fjob_detail%2F%3Fquery%3D%25E8%2587%25AA%25E5%258A%25A8%25E9%25A9%25BE%25E9%25A9%25B6%26city%3D101020100%26industry%3D%26position%3D; __zp_stoken__=eaf4AHdTnnRrM4tosXCE%2FCPA2IBqs%2BoMIR%2FkL2KsnUmYiwLERJs40PPb8KIurKugecg3l0jmgV1zyN86oQkjtd81dw%3D%3D; Hm_lpvt_194df3105ad7148dcf2b98a91b5e727a=1570159163; __a=64007787.1569672388.1570068443.1570153169.178.6.23.172; __zp_sseed__=4qNlVc1nPWG9Y7G66QfbgtQFW6iSHevalYp+HzrGFH4=; __zp_sname__=9d9e2c78; __zp_sts__=1570159388399'</span></span><br><span class="line">         }</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        html = requests.get(url,headers = header)</span><br><span class="line">        <span class="keyword">if</span> html.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> html.text <span class="comment">#返回列表页的html</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">except</span> RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br></pre></td></tr></tbody></table></figure><p>  获取到网页html后解析想要的数据，实现代码如下。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_job_detial</span><span class="params">(per_page_html)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> per_page_html==<span class="string">''</span> <span class="keyword">or</span> len(per_page_html)==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"未请求到列表页的html！"</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        jobs_title = []</span><br><span class="line">        area = []</span><br><span class="line">        work_exp = []</span><br><span class="line">        edu = []</span><br><span class="line">        company = []</span><br><span class="line">        salary = []</span><br><span class="line">        industry = []</span><br><span class="line">        financing_stage = []</span><br><span class="line">        company_scale = []</span><br><span class="line">        <span class="comment"># 初始化 标准化html</span></span><br><span class="line">        html = etree.HTML(per_page_html) </span><br><span class="line">        <span class="comment"># 工作名</span></span><br><span class="line">        jobs_title = html.xpath(<span class="string">'//div[@class="job-title"]/text()'</span>)</span><br><span class="line">        <span class="comment">#print(jobs_title)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment"># 工作地点</span></span><br><span class="line">        area = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[1]'</span>)</span><br><span class="line">        <span class="comment">#print(area)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#工作经验要求</span></span><br><span class="line">        work_exp = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[2]'</span>)</span><br><span class="line">        <span class="comment">#print(work_exp)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#学历要求</span></span><br><span class="line">        edu = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[3]'</span>)</span><br><span class="line">        <span class="comment">#print(edu)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#公司名</span></span><br><span class="line">        company = html.xpath(<span class="string">'//div[@class="company-text"]//a/text()'</span>)</span><br><span class="line">        <span class="comment">#print(company)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment"># 工资</span></span><br><span class="line">        salary = html.xpath(<span class="string">'//div[@class="info-primary"]//span[@class="red"]/text()'</span>)</span><br><span class="line">        <span class="comment">#print(salary)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#所属行业</span></span><br><span class="line">        industry = html.xpath(<span class="string">'//div[@class="info-company"]//p/text()[1]'</span>)</span><br><span class="line">        <span class="keyword">return</span> jobs_title,area,work_exp,edu,company,salary,industry</span><br></pre></td></tr></tbody></table></figure><p>  每次获取的是一页职位列表信息，需要将每次的数据尾加到总的数据<code>list</code>中，代码实现如下。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append_job_detial</span><span class="params">(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list,jobs_title,area,work_exp,edu,company,salary,industry)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i,info <span class="keyword">in</span> enumerate(jobs_title):</span><br><span class="line">        jobs_title_list.append(jobs_title[i])</span><br><span class="line">        area_list.append(area[i])</span><br><span class="line">        work_exp_list.append(work_exp[i])</span><br><span class="line">        edu_list.append(edu[i])</span><br><span class="line">        company_list.append(company[i])</span><br><span class="line">        salary_list.append(salary[i])</span><br><span class="line">        industry_list.append(industry[i])</span><br><span class="line">    <span class="keyword">return</span> jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list</span><br></pre></td></tr></tbody></table></figure><p>  当所有页面的数据获取解析完成后，将数据保存为Excel的形式，代码实现：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_excel</span><span class="params">(filename,sheet_name,data)</span>:</span></span><br><span class="line">    f = xlwt.Workbook(encoding=<span class="string">'utf-8'</span>)  <span class="comment">#创建一个Workbook 设置编码</span></span><br><span class="line">    <span class="comment"># 第二参数表示是否可以覆盖单元格 其实是 Workbook实例化的一个参数，默认值为False</span></span><br><span class="line">    sheet = f.add_sheet(sheet_name,cell_overwrite_ok=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，</span></span><br><span class="line">    <span class="comment"># 同时列出数据和数据下标，一般用在 for 循环当中。</span></span><br><span class="line">    <span class="keyword">for</span> row,row_data <span class="keyword">in</span> enumerate(data):  <span class="comment">#处理行</span></span><br><span class="line">        <span class="keyword">for</span> column,column_data <span class="keyword">in</span> enumerate(row_data): <span class="comment">#处理列</span></span><br><span class="line">            sheet.write(row,column,str(column_data))</span><br><span class="line">    f.save(filename + <span class="string">".xls"</span>)</span><br></pre></td></tr></tbody></table></figure><p>  对整个过程的代码集成如下。</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree <span class="comment">#xpath</span></span><br><span class="line"><span class="keyword">from</span> requests.exceptions <span class="keyword">import</span> RequestException</span><br><span class="line"><span class="keyword">import</span> xlwt       <span class="comment">#excel操作</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_job_html</span><span class="params">(url)</span>:</span></span><br><span class="line">    header = {</span><br><span class="line">         <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/77.0.3865.90 Safari/537.36'</span>,</span><br><span class="line">         <span class="string">'Cookie'</span>:<span class="string">'_uab_collina=156967238793885639512262; bannerClose_wanmeishijie=true; lastCity=101010100; _bl_uid=q5k7F1m8aOIjLLybtrIhbILink0X; __c=1570153169; __g=-; Hm_lvt_194df3105ad7148dcf2b98a91b5e727a=1569912508,1569985933,1570068443,1570153169; __l=l=%2Fwww.zhipin.com%2F&amp;r=&amp;friend_source=0&amp;friend_source=0; toUrl=https%3A%2F%2Fwww.zhipin.com%2Fjob_detail%2F%3Fquery%3D%25E8%2587%25AA%25E5%258A%25A8%25E9%25A9%25BE%25E9%25A9%25B6%26city%3D101020100%26industry%3D%26position%3D; __zp_stoken__=eaf4AHdTnnRrM4tosXCE%2FCPA2IBqs%2BoMIR%2FkL2KsnUmYiwLERJs40PPb8KIurKugecg3l0jmgV1zyN86oQkjtd81dw%3D%3D; Hm_lpvt_194df3105ad7148dcf2b98a91b5e727a=1570159163; __a=64007787.1569672388.1570068443.1570153169.178.6.23.172; __zp_sseed__=4qNlVc1nPWG9Y7G66QfbgtQFW6iSHevalYp+HzrGFH4=; __zp_sname__=9d9e2c78; __zp_sts__=1570159388399'</span></span><br><span class="line">         }</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        html = requests.get(url,headers = header)</span><br><span class="line">        <span class="keyword">if</span> html.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> html.text <span class="comment">#返回列表页的html</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">except</span> RequestException:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_job_detial</span><span class="params">(per_page_html)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> per_page_html==<span class="string">''</span> <span class="keyword">or</span> len(per_page_html)==<span class="number">0</span>:</span><br><span class="line">        print(<span class="string">"未请求到列表页的html！"</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        jobs_title = []</span><br><span class="line">        area = []</span><br><span class="line">        work_exp = []</span><br><span class="line">        edu = []</span><br><span class="line">        company = []</span><br><span class="line">        salary = []</span><br><span class="line">        industry = []</span><br><span class="line">        financing_stage = []</span><br><span class="line">        company_scale = []</span><br><span class="line">        <span class="comment"># 初始化 标准化html</span></span><br><span class="line">        html = etree.HTML(per_page_html) </span><br><span class="line">        <span class="comment"># 工作名</span></span><br><span class="line">        jobs_title = html.xpath(<span class="string">'//div[@class="job-title"]/text()'</span>)</span><br><span class="line">        <span class="comment">#print(jobs_title)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment"># 工作地点</span></span><br><span class="line">        area = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[1]'</span>)</span><br><span class="line">        <span class="comment">#print(area)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#工作经验要求</span></span><br><span class="line">        work_exp = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[2]'</span>)</span><br><span class="line">        <span class="comment">#print(work_exp)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#学历要求</span></span><br><span class="line">        edu = html.xpath(<span class="string">'//div[@class="info-primary"]//p/text()[3]'</span>)</span><br><span class="line">        <span class="comment">#print(edu)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#公司名</span></span><br><span class="line">        company = html.xpath(<span class="string">'//div[@class="company-text"]//a/text()'</span>)</span><br><span class="line">        <span class="comment">#print(company)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment"># 工资</span></span><br><span class="line">        salary = html.xpath(<span class="string">'//div[@class="info-primary"]//span[@class="red"]/text()'</span>)</span><br><span class="line">        <span class="comment">#print(salary)</span></span><br><span class="line">        <span class="comment">#a = 1</span></span><br><span class="line">        <span class="comment">#所属行业</span></span><br><span class="line">        industry = html.xpath(<span class="string">'//div[@class="info-company"]//p/text()[1]'</span>)</span><br><span class="line">        <span class="keyword">return</span> jobs_title,area,work_exp,edu,company,salary,industry</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append_job_detial</span><span class="params">(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list,jobs_title,area,work_exp,edu,company,salary,industry)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i,info <span class="keyword">in</span> enumerate(jobs_title):</span><br><span class="line">        jobs_title_list.append(jobs_title[i])</span><br><span class="line">        area_list.append(area[i])</span><br><span class="line">        work_exp_list.append(work_exp[i])</span><br><span class="line">        edu_list.append(edu[i])</span><br><span class="line">        company_list.append(company[i])</span><br><span class="line">        salary_list.append(salary[i])</span><br><span class="line">        industry_list.append(industry[i])</span><br><span class="line">    <span class="keyword">return</span> jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_excel</span><span class="params">(filename,sheet_name,data)</span>:</span></span><br><span class="line">    f = xlwt.Workbook(encoding=<span class="string">'utf-8'</span>)  <span class="comment">#创建一个Workbook 设置编码</span></span><br><span class="line">    <span class="comment"># 第二参数表示是否可以覆盖单元格 其实是 Workbook实例化的一个参数，默认值为False</span></span><br><span class="line">    sheet = f.add_sheet(sheet_name,cell_overwrite_ok=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，</span></span><br><span class="line">    <span class="comment"># 同时列出数据和数据下标，一般用在 for 循环当中。</span></span><br><span class="line">    <span class="keyword">for</span> row,row_data <span class="keyword">in</span> enumerate(data):  <span class="comment">#处理行</span></span><br><span class="line">        <span class="keyword">for</span> column,column_data <span class="keyword">in</span> enumerate(row_data): <span class="comment">#处理列</span></span><br><span class="line">            sheet.write(row,column,str(column_data))</span><br><span class="line">    f.save(filename + <span class="string">".xls"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_detial</span><span class="params">(total_page_count)</span>:</span></span><br><span class="line">    <span class="comment">#循环所有页面，</span></span><br><span class="line">    <span class="comment">#第一步，构造URL获取html</span></span><br><span class="line">    <span class="comment">#第二步，使用bs4解析详情页的超链接，保存到数组中</span></span><br><span class="line">    key_words = <span class="string">"自动驾驶"</span></span><br><span class="line">    key = urllib.parse.quote(key_words) <span class="comment">#将中文进行转码</span></span><br><span class="line">    jobs_title_list = []</span><br><span class="line">    area_list = []</span><br><span class="line">    work_exp_list = []</span><br><span class="line">    edu_list = []</span><br><span class="line">    company_list = []</span><br><span class="line">    salary_list = []</span><br><span class="line">    industry_list = []</span><br><span class="line">    financing_stage_list = []</span><br><span class="line">    company_scale_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,total_page_count+<span class="number">1</span>):   <span class="comment">#查看页面有10页职位列表</span></span><br><span class="line">        print(<span class="string">"正在爬取第 %s 页列表页..."</span> % i)</span><br><span class="line">        url =<span class="string">'https://www.zhipin.com/c100010000/?query='</span>+key+<span class="string">'&amp;page='</span>+str(i)+<span class="string">'&amp;ka=page-'</span>+str(i)</span><br><span class="line">        <span class="comment">#获取每页的列表html</span></span><br><span class="line">        per_page_html = get_job_html(url) </span><br><span class="line">        <span class="comment">#解析提取详情页超的数据</span></span><br><span class="line">        jobs_title,area,work_exp,edu,company,salary,industry\</span><br><span class="line">            =  parse_job_detial(per_page_html) <span class="comment">#,company_scale,financing_stage</span></span><br><span class="line">        <span class="comment"># 将每页30个数据尾加到总的数组</span></span><br><span class="line">        jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list\</span><br><span class="line">            = append_job_detial(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list,\</span><br><span class="line">                jobs_title,area,work_exp,edu,company,salary,industry) <span class="comment">#,financing_stage_list,financing_stage,financing_stage_list,company_scale,,company_scale_list,company_scale_list,</span></span><br><span class="line">        <span class="comment">#随机等待,防止封ip</span></span><br><span class="line">        span=round(random.random()*<span class="number">6</span>,<span class="number">1</span>)</span><br><span class="line">        time.sleep(span)</span><br><span class="line">    print(<span class="string">"爬取列表页完成！"</span>)</span><br><span class="line">    <span class="comment"># 将爬取的数据保存到Excel</span></span><br><span class="line">    jobs_data = list(zip(jobs_title_list,area_list,work_exp_list,edu_list,company_list,salary_list,industry_list)) <span class="comment">#,company_scale_list</span></span><br><span class="line">    jobs_data.insert(<span class="number">0</span>, (<span class="string">"岗位"</span>,<span class="string">"工作地点"</span>,<span class="string">"工作经验要求"</span>,<span class="string">"学历要求"</span>,<span class="string">"招聘公司"</span>,<span class="string">"工资"</span>,<span class="string">"所属行业"</span>))  <span class="comment">#,"公司规模"</span></span><br><span class="line">    save_to_excel(<span class="string">"jobData"</span>, <span class="string">"AutoDriving"</span>, jobs_data) <span class="comment">#fileName,SheetName,数据</span></span><br><span class="line">    print(<span class="string">"保存数据成功，打开jobData.xls查看"</span>)</span><br><span class="line"></span><br><span class="line">total_page_count = <span class="number">10</span> <span class="comment">#设置爬取列表页页数，10页</span></span><br><span class="line">get_all_detial(total_page_count) <span class="comment">#获取工作的数据保存到Excel</span></span><br></pre></td></tr></tbody></table></figure><img title="获取的数据" data-src="/2019/10/17/BOSS直聘爬虫/图1-4获取的数据.png"><center>图1-4  获取的数据</center><p>  图1-4为获取的目标数据，一共抓取了120个岗位信息。下一步就是对获取的信息进行清洗和统计分析。</p><h2 id="二、数据分析"><a href="#二、数据分析" class="headerlink" title="二、数据分析"></a>二、数据分析</h2><p>  本节主要介绍我们关心哪些信息，并如何对这些的数据进行分析处理和可视化，从而从这些数据中提取出有价值的信息。</p><h3 id="2-1-工作地点全国分布"><a href="#2-1-工作地点全国分布" class="headerlink" title="2.1 工作地点全国分布"></a>2.1 工作地点全国分布</h3><p>  找工作首先关注的点应该是“在哪”工作，找到一个房价便宜工资很高的工作应该是绝大多数求职者的最佳选择。那么“自动驾驶”相关岗位在全国范围内的分布是什么样的情况，本文通过使用优秀的可视化包pyecharts<sup>[1]</sup>实现对招聘岗位全国的分布情况的分析。</p><p><strong>在制作过程中pyecharts的<span class="exturl" data-url="aHR0cHM6Ly9weWVjaGFydHMub3JnLyMvemgtY24v" title="https://pyecharts.org/#/zh-cn/">官方文档<i class="fa fa-external-link"></i></span>起到了很大的作用，以后在开发过程中要重视官方文档的使用。</strong></p><img title="图2-1 自动驾驶职位招聘全国分布" data-src="/2019/10/17/BOSS直聘爬虫/图2-1%20自动驾驶职位招聘全国分布.png"><center>图2-1 自动驾驶职位招聘全国分布</center><img title="图2-2  自动驾驶岗位数量全国TOP10城市" data-src="/2019/10/17/BOSS直聘爬虫/图2-2%20%20自动驾驶岗位数量全国TOP10城市.png"><center>图2-2  自动驾驶岗位数量全国TOP10城市</center><p>  从图中可以看出“自动驾驶”岗位主要分布在北京、上海、深圳、武汉、苏州、杭州等一线、二线城市，北京、江浙沪（包邮区）和深圳是主要阵地，如果想要从事这个领域的工作，到这些城市去发展有好的环境。</p><h3 id="2-2-薪资水平"><a href="#2-2-薪资水平" class="headerlink" title="2.2 薪资水平"></a>2.2 薪资水平</h3><p>  找工作更重要的是薪资的水平，辛辛苦苦学了很多技能和知识就是为了获得更多的薪资。所以我们来看一下“自动驾驶”岗位的全国范围的薪资水平是怎样的。本文对获取的数据按照城市分类，计算了各个城市的平均薪资水平，如图2-3所示。</p><img title="图2-3  自动驾驶全国平均薪资水平统计" data-src="/2019/10/17/BOSS直聘爬虫/图2-3%20%20自动驾驶全国平均薪资水平统计.png"><center>图2-3  自动驾驶全国平均薪资水平统计</center><p>  从图中可以看出，杭州以35K的平均月薪位居全国第一，全国范围内的平均薪资为18422元/月，佛山最低仅有5000元/月。月薪超过全国平均水平的数量超总体的60%。可以看出，薪资水平最高的城市在杭州、北京、上海、深圳等一线城市，杭州的物价水平和房价低于北上广等城市，落户和生活的成本与北上广相比较低，是一个不错的选择。</p><h3 id="2-3-学历、工作经验要求"><a href="#2-3-学历、工作经验要求" class="headerlink" title="2.3 学历、工作经验要求"></a>2.3 学历、工作经验要求</h3><p>  你可能会问这些岗位这么好，会对学历有很高的要求吗？（学历在不同行业都是越高越好吗？）对工作经验又有什么样的要求呢？那么我们就通过数据来看一下结果吧，通过对所获取信息中的学历要求、工作经验进行统计，绘制“自动驾驶”职位学历要求饼图、工作经验要求饼图如图2-4和图2-5所示。</p><img title="图2-4  “自动驾驶”职位学历要求" data-src="/2019/10/17/BOSS直聘爬虫/图2-4%20%20“自动驾驶”职位学历要求.png"><center>图2-4  “自动驾驶”职位学历要求</center><img title="图2-5  “自动驾驶”职位工作经验要求" data-src="/2019/10/17/BOSS直聘爬虫/图2-5%20%20“自动驾驶”职位工作经验要求.png"><center>图2-5  “自动驾驶”职位工作经验要求</center><p>  通过统计结果可以看出，在获取的岗位招聘信息中，自动驾驶相关岗位对学历的要求不是很高，本科学历要求占75%以上，硕士学历要求占15%左右。结合经验要求来看，大部分的公司要求是经验不限和1-5年，这几个时间范围占了主要部分，所以结合这两个信息，认为“自动驾驶”岗位更加看重工作经验，只要有本科的学历，经验丰富能力强就可以找到不错的工作。</p><h3 id="2-4-工作种类、主要企业、行业分布"><a href="#2-4-工作种类、主要企业、行业分布" class="headerlink" title="2.4 工作种类、主要企业、行业分布"></a>2.4 工作种类、主要企业、行业分布</h3><p>  分析完学历与工作经验，我们来分析一下这些工作主要包括哪些种类，也就是说“自动驾驶”的招聘岗位主要包括哪些，可以为求职者提供学习的方向。为了更好地展示数据分析的成果，我们使用了优秀的开源包<span class="exturl" data-url="aHR0cHM6Ly9weXBpLm9yZy9wcm9qZWN0L2ppZWJhLw==" title="https://pypi.org/project/jieba/">jieba<i class="fa fa-external-link"></i></span>以及强大、方便的可视化工具<span class="exturl" data-url="aHR0cHM6Ly9weXBpLm9yZy9wcm9qZWN0L3B5ZWNoYXJ0cy8=" title="https://pypi.org/project/pyecharts/">pyecharts<i class="fa fa-external-link"></i></span>展示，根据“工作名”这一项数据项先进行分词，然后绘制了词云如图2-6所示。</p><img title="图2-6  “自动驾驶”主要岗位种类分析" data-src="/2019/10/17/BOSS直聘爬虫/图2-6%20%20“自动驾驶”主要岗位种类分析.png"><center>图2-6  “自动驾驶”主要岗位种类分析</center><p>  从图中可以看出，<code>算法</code>、<code>规划</code>、<code>感知</code>、<code>控制</code>、<code>嵌入式</code>等关键词频率较高，所以想要从事这一领域的工作，可以多多关注和学习这些领域的知识。为以后的求职做好准备，打下基础。<br>  那么哪些公司是招聘的大户呢？即招聘岗位数量较多的企业有哪些？我们使用同样的方法绘制了基于企业招聘数量的词云如图2-7所示。</p><img title="图2-7  “自动驾驶”主要招聘企业" data-src="/2019/10/17/BOSS直聘爬虫/图2-7%20%20“自动驾驶”主要招聘企业.png"><center>图2-7  “自动驾驶”主要招聘企业</center><p>  可以看出，招聘数量排在前几位的分别有禾多科技、<span class="exturl" data-url="aHR0cHM6Ly93d3cuZGVlcGJsdWVhaS5jb20=" title="https://www.deepblueai.com">深兰科技<i class="fa fa-external-link"></i></span>、<span class="exturl" data-url="aHR0cHM6Ly93d3cuY3Rpcm9ib3QuY29t" title="https://www.ctirobot.com">坎德拉<i class="fa fa-external-link"></i></span>、<span class="exturl" data-url="aHR0cDovL3d3dy41MWhpdGVjaC5jb20=" title="http://www.51hitech.com">51VR<i class="fa fa-external-link"></i></span>、<span class="exturl" data-url="aHR0cDovL3d3dy5rb3RlaS5jb20uY24=" title="http://www.kotei.com.cn">武汉光庭科技<i class="fa fa-external-link"></i></span>、<span class="exturl" data-url="aHR0cDovL3d3dy55aWhhbmcuYWk=" title="http://www.yihang.ai">易航<i class="fa fa-external-link"></i></span>等公司，互联网大厂腾讯、华为，传统车厂吉利集团紧随其后，还有很多年轻的企业也有上榜。</p><p>  这些岗位所属的行业又有哪些呢？我们使用同样的方法统计如图2-8所示。</p><img title="图2-8  自动驾驶招聘行业分布" data-src="/2019/10/17/BOSS直聘爬虫/图2-8%20%20自动驾驶招聘行业分布.png"><center>图2-8  自动驾驶招聘行业分布</center><p>  从图中可以看出现在“自动驾驶”的企业所示行业多为“计算机互联网”、“智能硬件”以及“汽车生产”行业，这三类行业是招聘的主力军。</p><h2 id="三、总结与讨论"><a href="#三、总结与讨论" class="headerlink" title="三、总结与讨论"></a>三、总结与讨论</h2><h3 id="3-1-总结"><a href="#3-1-总结" class="headerlink" title="3.1 总结"></a>3.1 总结</h3><p>从两个方面进行总结，</p><ul><li><p>首先是内容上：从数据的分析中对于<strong>自动驾驶</strong>岗位的招聘需求有了进一步的认识，自动驾驶相关岗位主要的工作内容有<strong>算法、规划、感知、控制、嵌入式</strong>，北京、江浙沪（包邮区）和深圳是主要的工作地点，全国范围内的平均薪资为18422元/月，自动驾驶岗位更加看重工作经验、学历多数要求为本科，所在行业一般为<strong>计算机互联网、智能硬件以及汽车生产</strong>，招聘需求较多的企业有禾多科技、深兰科技、坎德拉、51VR、武汉光庭科技、易航等公司。</p></li><li><p>其次是技术上总结：<br>在数据获取中学会使用开发者工具发现网页规律；在数据解析中学会使用<code>xpath</code>、<code>beautifulSoup</code>；数据分析中学会使用<code>pyecharts</code>绘制多种有趣的可视化图片，学会使用<code>jieba</code>包统计词频。</p></li></ul><h3 id="3-2-遇到的问题"><a href="#3-2-遇到的问题" class="headerlink" title="3.2 遇到的问题"></a>3.2 遇到的问题</h3><p>  本文一开始想要获取更详细的<code>工作职责</code>和<code>工作技能要求</code>的数据，在爬取详情页的过程中发现BOSS直聘在请求详情页时每次的请求都会产生不同的<code>cookie</code>，否则无法获取想要的html，会跳转到其他页面，经过google查询已经有前辈发现了这个问题，但是还未找到解决的反反爬方法（魔高一尺道高一丈）。所以改为爬取较为容易获取的详情页面。</p><h3 id="3-3-不足之处"><a href="#3-3-不足之处" class="headerlink" title="3.3 不足之处"></a>3.3 不足之处</h3><p>  本文仅仅分析了BOSS直聘一家的数据，数据来源与实际情况有一定的差别，但是能体现一定的代表性，未来可以进行多家招聘网站（如<strong>智联招聘、51job招聘，前程无忧</strong>等）的数据爬取，提高数据的可信度。</p><h3 id="3-4-未来工作"><a href="#3-4-未来工作" class="headerlink" title="3.4 未来工作"></a>3.4 未来工作</h3><p>  目前已经完成数据的<code>获取、分析、统计、可视化</code>，未来还可以对数据之间的<code>相关性</code>进行<code>建模分析</code>，得出有意思、有价值的结论。（例如，哪些数据对薪资有影响？）</p><h3 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h3><p>  <em>本文的主要方法与技术代码参考了网络上的博客，在此一并致谢！</em></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>[1]    LI D, MEI H, YI S, et al. ECharts: A declarative framework for rapid construction of web-based visualization ☆ [J]. Visual Informatics, 2018, S2468502X18300068-.</p><p>[2] <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyMjkzNzU4L2FydGljbGUvZGV0YWlscy84ODU3MzM2MA==" title="https://blog.csdn.net/qq_42293758/article/details/88573360">Python爬取岗位数据并分析<i class="fa fa-external-link"></i></span></p><p>[3] <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzkzMDY5NC9hcnRpY2xlL2RldGFpbHMvOTY2NTAyODE=" title="https://blog.csdn.net/weixin_43930694/article/details/96650281">Python3 + xpath + excel 实现对boss直聘网的爬取<i class="fa fa-external-link"></i></span></p><p>[4] <span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzI3NjY4MzEzL2FydGljbGUvZGV0YWlscy84MjkyNDYyMg==" title="https://blog.csdn.net/qq_27668313/article/details/82924622">BOSS直聘网站数据分析岗位信息爬取<i class="fa fa-external-link"></i></span></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;  这是我个人博客的第一篇文章，是全新的开始。希望未来在这里记录更多有趣的探索。&lt;/p&gt;
&lt;img title=&quot;自动驾驶岗位名称&quot; data-src=&quot;/2019/10/17/BOSS直聘爬虫/岗位名称.jpg&quot;&gt;
&lt;p&gt;  自动驾驶随着人工智能技术的成熟，人才需求在不断增加，为了对我国自动驾驶人才需求进行了解，本文选择&lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly93d3cuemhpcGluLmNvbQ==&quot; title=&quot;https://www.zhipin.com&quot;&gt;BOSS直聘&lt;i class=&quot;fa fa-external-link&quot;&gt;&lt;/i&gt;&lt;/span&gt;招聘网站获取自动驾驶相关职位信息，分析数据，根据分析结果确定人才需求、为以后的学习制定计划。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="2019秋《交通数据分析》" scheme="http://www.caoxu.club/categories/2019%E7%A7%8B%E3%80%8A%E4%BA%A4%E9%80%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%8B/"/>
    
      <category term="数据爬取" scheme="http://www.caoxu.club/categories/2019%E7%A7%8B%E3%80%8A%E4%BA%A4%E9%80%9A%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E3%80%8B/%E6%95%B0%E6%8D%AE%E7%88%AC%E5%8F%96/"/>
    
    
      <category term="python" scheme="http://www.caoxu.club/tags/python/"/>
    
      <category term="爬虫" scheme="http://www.caoxu.club/tags/%E7%88%AC%E8%99%AB/"/>
    
      <category term="工作信息" scheme="http://www.caoxu.club/tags/%E5%B7%A5%E4%BD%9C%E4%BF%A1%E6%81%AF/"/>
    
      <category term="可视化" scheme="http://www.caoxu.club/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"/>
    
      <category term="pyecharts" scheme="http://www.caoxu.club/tags/pyecharts/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://www.caoxu.club/2019/10/12/hello-world/"/>
    <id>http://www.caoxu.club/2019/10/12/hello-world/</id>
    <published>2019-10-12T13:25:37.410Z</published>
    <updated>2019-10-14T16:39:38.421Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvLw==" title="https://hexo.io/">Hexo<i class="fa fa-external-link"></i></span>! This is your very first post. Check <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL2RvY3Mv" title="https://hexo.io/docs/">documentation<i class="fa fa-external-link"></i></span> for more info. If you get any problems when using Hexo, you can find the answer in <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL2RvY3MvdHJvdWJsZXNob290aW5nLmh0bWw=" title="https://hexo.io/docs/troubleshooting.html">troubleshooting<i class="fa fa-external-link"></i></span> or you can ask me on <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2hleG9qcy9oZXhvL2lzc3Vlcw==" title="https://github.com/hexojs/hexo/issues">GitHub<i class="fa fa-external-link"></i></span>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></tbody></table></figure><p>More info: <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvd3JpdGluZy5odG1s" title="https://hexo.io/docs/writing.html">Writing<i class="fa fa-external-link"></i></span></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></tbody></table></figure><p>More info: <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL2RvY3Mvc2VydmVyLmh0bWw=" title="https://hexo.io/docs/server.html">Server<i class="fa fa-external-link"></i></span></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></tbody></table></figure><p>More info: <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL2RvY3MvZ2VuZXJhdGluZy5odG1s" title="https://hexo.io/docs/generating.html">Generating<i class="fa fa-external-link"></i></span></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></tbody></table></figure><p>More info: <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlvL2RvY3MvZGVwbG95bWVudC5odG1s" title="https://hexo.io/docs/deployment.html">Deployment<i class="fa fa-external-link"></i></span></p><script>        document.querySelectorAll('.github-emoji')          .forEach(el => {            if (!el.dataset.src) { return; }            const img = document.createElement('img');            img.style = 'display:none !important;';            img.src = el.dataset.src;            img.addEventListener('error', () => {              img.remove();              el.style.color = 'inherit';              el.style.backgroundImage = 'none';              el.style.background = 'none';            });            img.addEventListener('load', () => {              img.remove();            });            document.body.appendChild(img);          });      </script>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;span class=&quot;exturl&quot; data-url=&quot;aHR0cHM6Ly9oZXhvLmlvLw==&quot; title=&quot;https://hexo.io/&quot;&gt;Hexo&lt;i class=&quot;fa fa-external-link&quot;&gt;&lt;/i&gt;&lt;/spa
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
